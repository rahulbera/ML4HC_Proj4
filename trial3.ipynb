{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_seq shape: (29420,)\n",
      "test_seq shape: (33333,)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence, text\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#train_data_source = './exercise_data/human_dna_train_small.csv'\n",
    "train_data_source = './exercise_data/human_dna_train_split_5_95.csv'\n",
    "val_data_source = './exercise_data/human_dna_validation_split.csv'\n",
    "test_data_source = './exercise_data/human_dna_test_split.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_data_source, header=0)\n",
    "test_df = pd.read_csv(test_data_source, header=0)\n",
    "\n",
    "train_seq = train_df['sequences']\n",
    "train_label = train_df['labels']\n",
    "test_seq = test_df['sequences']\n",
    "test_label = test_df['labels']\n",
    "\n",
    "# Preprocess\n",
    "tk = text.Tokenizer(char_level=True)\n",
    "tk.fit_on_texts(train_seq)\n",
    "\n",
    "train_seq_tok = tk.texts_to_sequences(train_seq)\n",
    "test_seq_tok = tk.texts_to_sequences(test_seq)\n",
    "\n",
    "train_seq = np.array(train_seq)\n",
    "train_seq_tok = np.array(train_seq_tok)\n",
    "train_label = np.array(train_label)\n",
    "test_seq = np.array(test_seq)\n",
    "test_seq_tok = np.array(test_seq_tok)\n",
    "test_label = np.array(test_label)\n",
    "\n",
    "print('train_seq shape:', train_seq.shape)\n",
    "print('test_seq shape:', test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label[train_label<0]=0\n",
    "test_label[test_label<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_tok = train_seq_tok - np.ones(shape=train_seq_tok.shape)\n",
    "test_seq_tok = test_seq_tok - np.ones(shape=test_seq_tok.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 3., 1., ..., 1., 0., 1.],\n",
       "       [0., 2., 2., ..., 0., 0., 0.],\n",
       "       [1., 2., 2., ..., 1., 2., 0.],\n",
       "       ...,\n",
       "       [2., 0., 0., ..., 1., 1., 2.],\n",
       "       [1., 3., 1., ..., 2., 1., 1.],\n",
       "       [2., 0., 0., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_tok_split = np.hsplit(train_seq_tok, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29420, 398)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq_tok.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29420, 199)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq_tok_split[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 3., 1., 1., 2., 1., 2., 2., 0., 0., 1., 1., 2., 3., 1., 1., 3.,\n",
       "       0., 0., 2., 0., 2., 2., 1., 0., 2., 2., 0., 3., 1., 0., 2., 2., 1.,\n",
       "       3., 2., 1., 0., 1., 2., 2., 2., 1., 1., 3., 0., 1., 0., 0., 2., 3.,\n",
       "       1., 1., 1., 0., 0., 3., 0., 0., 2., 1., 2., 3., 1., 0., 2., 2., 0.,\n",
       "       2., 0., 0., 2., 1., 3., 1., 2., 2., 2., 1., 1., 2., 1., 1., 1., 1.,\n",
       "       3., 1., 2., 0., 1., 0., 0., 3., 3., 1., 2., 1., 0., 3., 1., 2., 0.,\n",
       "       0., 1., 2., 0., 2., 0., 2., 2., 3., 1., 2., 0., 1., 1., 1., 1., 3.,\n",
       "       1., 3., 1., 0., 2., 1., 2., 2., 2., 2., 0., 2., 1., 3., 0., 2., 1.,\n",
       "       1., 2., 2., 2., 1., 1., 2., 3., 1., 2., 3., 1., 1., 1., 1., 1., 3.,\n",
       "       0., 2., 2., 3., 1., 2., 1., 1., 1., 1., 1., 1., 3., 1., 1., 2., 3.,\n",
       "       1., 2., 3., 0., 3., 0., 0., 0., 3., 0., 3., 0., 2., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 2., 3., 3., 1., 1., 1., 2., 2., 1., 0., 1., 3.,\n",
       "       3., 0., 3., 3., 3., 0., 3., 1., 1., 3., 1., 1., 0., 2., 2., 2., 3.,\n",
       "       1., 0., 0., 3., 3., 0., 1., 2., 2., 2., 1., 2., 3., 1., 0., 3., 1.,\n",
       "       0., 0., 1., 1., 3., 1., 1., 2., 1., 0., 0., 3., 3., 1., 2., 3., 0.,\n",
       "       3., 0., 1., 3., 0., 3., 3., 0., 0., 3., 3., 0., 2., 3., 0., 2., 1.,\n",
       "       2., 2., 0., 0., 0., 2., 0., 3., 2., 3., 0., 0., 1., 1., 2., 1., 1.,\n",
       "       0., 3., 0., 2., 2., 1., 2., 1., 3., 1., 2., 2., 0., 1., 2., 2., 2.,\n",
       "       0., 2., 3., 1., 2., 0., 2., 2., 3., 0., 0., 1., 3., 1., 3., 3., 0.,\n",
       "       2., 0., 1., 1., 0., 3., 3., 0., 1., 2., 3., 1., 3., 0., 0., 0., 2.,\n",
       "       2., 2., 1., 2., 2., 3., 3., 1., 1., 2., 2., 3., 2., 0., 2., 0., 1.,\n",
       "       2., 1., 0., 3., 1., 3., 3., 0., 2., 1., 2., 2., 0., 3., 1., 2., 2.,\n",
       "       1., 2., 0., 0., 3., 1., 1., 3., 1., 3., 3., 1., 2., 3., 3., 0., 2.,\n",
       "       1., 3., 3., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq_tok_split = np.hsplit(test_seq_tok, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 3., 1., 1., 2., 1., 2., 2., 0., 0., 1., 1., 2., 3., 1., 1., 3.,\n",
       "       0., 0., 2., 0., 2., 2., 1., 0., 2., 2., 0., 3., 1., 0., 2., 2., 1.,\n",
       "       3., 2., 1., 0., 1., 2., 2., 2., 1., 1., 3., 0., 1., 0., 0., 2., 3.,\n",
       "       1., 1., 1., 0., 0., 3., 0., 0., 2., 1., 2., 3., 1., 0., 2., 2., 0.,\n",
       "       2., 0., 0., 2., 1., 3., 1., 2., 2., 2., 1., 1., 2., 1., 1., 1., 1.,\n",
       "       3., 1., 2., 0., 1., 0., 0., 3., 3., 1., 2., 1., 0., 3., 1., 2., 0.,\n",
       "       0., 1., 2., 0., 2., 0., 2., 2., 3., 1., 2., 0., 1., 1., 1., 1., 3.,\n",
       "       1., 3., 1., 0., 2., 1., 2., 2., 2., 2., 0., 2., 1., 3., 0., 2., 1.,\n",
       "       1., 2., 2., 2., 1., 1., 2., 3., 1., 2., 3., 1., 1., 1., 1., 1., 3.,\n",
       "       0., 2., 2., 3., 1., 2., 1., 1., 1., 1., 1., 1., 3., 1., 1., 2., 3.,\n",
       "       1., 2., 3., 0., 3., 0., 0., 0., 3., 0., 3., 0., 2., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 2., 3., 3., 1., 1., 1., 2.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq_tok_split[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 29420 samples, validate on 33333 samples\n",
      "Epoch 1/200\n",
      "29420/29420 [==============================] - 3s 102us/step - loss: 0.2063 - acc: 0.9500 - recall_m: 0.0000e+00 - precision_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.0702 - val_acc: 0.9969 - val_recall_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/200\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.1930 - acc: 0.9500 - recall_m: 0.0000e+00 - precision_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.0656 - val_acc: 0.9969 - val_recall_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/200\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.1807 - acc: 0.9500 - recall_m: 0.0000e+00 - precision_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.0422 - val_acc: 0.9969 - val_recall_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/200\n",
      "29420/29420 [==============================] - 3s 85us/step - loss: 0.1708 - acc: 0.9500 - recall_m: 0.0000e+00 - precision_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.0626 - val_acc: 0.9968 - val_recall_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/200\n",
      "29420/29420 [==============================] - 3s 86us/step - loss: 0.1635 - acc: 0.9500 - recall_m: 7.2464e-04 - precision_m: 0.0022 - f1_m: 0.0011 - val_loss: 0.0728 - val_acc: 0.9967 - val_recall_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/200\n",
      "29420/29420 [==============================] - 3s 86us/step - loss: 0.1547 - acc: 0.9505 - recall_m: 0.0185 - precision_m: 0.0511 - f1_m: 0.0253 - val_loss: 0.0593 - val_acc: 0.9952 - val_recall_m: 0.0019 - val_precision_m: 0.0019 - val_f1_m: 0.0019\n",
      "Epoch 7/200\n",
      "29420/29420 [==============================] - 3s 86us/step - loss: 0.1466 - acc: 0.9515 - recall_m: 0.0570 - precision_m: 0.1630 - f1_m: 0.0789 - val_loss: 0.0540 - val_acc: 0.9947 - val_recall_m: 0.0019 - val_precision_m: 0.0019 - val_f1_m: 0.0019\n",
      "Epoch 8/200\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.1371 - acc: 0.9532 - recall_m: 0.1147 - precision_m: 0.2618 - f1_m: 0.1476 - val_loss: 0.0559 - val_acc: 0.9927 - val_recall_m: 0.0019 - val_precision_m: 0.0019 - val_f1_m: 0.0019\n",
      "Epoch 9/200\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.1262 - acc: 0.9555 - recall_m: 0.1828 - precision_m: 0.3694 - f1_m: 0.2246 - val_loss: 0.0788 - val_acc: 0.9823 - val_recall_m: 0.0067 - val_precision_m: 0.0045 - val_f1_m: 0.0052\n",
      "Epoch 10/200\n",
      "29420/29420 [==============================] - 3s 86us/step - loss: 0.1146 - acc: 0.9590 - recall_m: 0.2722 - precision_m: 0.4782 - f1_m: 0.3209 - val_loss: 0.0466 - val_acc: 0.9915 - val_recall_m: 0.0038 - val_precision_m: 0.0038 - val_f1_m: 0.0038\n",
      "Epoch 11/200\n",
      "29420/29420 [==============================] - 2s 85us/step - loss: 0.1021 - acc: 0.9631 - recall_m: 0.3526 - precision_m: 0.6253 - f1_m: 0.4183 - val_loss: 0.0616 - val_acc: 0.9831 - val_recall_m: 0.0077 - val_precision_m: 0.0064 - val_f1_m: 0.0067\n",
      "Epoch 12/200\n",
      "29420/29420 [==============================] - 3s 86us/step - loss: 0.0877 - acc: 0.9681 - recall_m: 0.4411 - precision_m: 0.6587 - f1_m: 0.4982 - val_loss: 0.0806 - val_acc: 0.9729 - val_recall_m: 0.0154 - val_precision_m: 0.0094 - val_f1_m: 0.0111\n",
      "Epoch 13/200\n",
      "29420/29420 [==============================] - 3s 86us/step - loss: 0.0758 - acc: 0.9730 - recall_m: 0.5486 - precision_m: 0.7351 - f1_m: 0.5921 - val_loss: 0.0461 - val_acc: 0.9879 - val_recall_m: 0.0038 - val_precision_m: 0.0038 - val_f1_m: 0.0038\n",
      "Epoch 00013: early stopping\n",
      "33333/33333 [==============================] - 1s 20us/step\n",
      "Test score: 0.04614791714164173\n",
      "Test accuracy: 0.9878798723220825\n",
      "Test recall: 0.0038387710228562355\n",
      "Test precision: 0.0038387710228562355\n",
      "Test F1: 0.0038387710228562355\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3hUZfbA8e9JIaG3hJYEEopIlZIgRZoChiJgoyiIFRu7loUV9+eurruurLp2RBEQURARQUBAQCkCghB6h1CT0IkgBELa+/vjHTTGICGZyZ1kzud58jBz25xLJvfc+1YxxqCUUsr3+DkdgFJKKWdoAlBKKR+lCUAppXyUJgCllPJRmgCUUspHBTgdwNUICQkxkZGRToehlFJFyrp1604aY0JzLi9SCSAyMpK4uDinw1BKqSJFRA7mtlyLgJRSykdpAlBKKR+lCUAppXxUkaoDUEqpq5Wenk5iYiKpqalOh+JxwcHBhIeHExgYmKftNQEopYq1xMREypYtS2RkJCLidDgeY4zh1KlTJCYmEhUVlad9tAhIKVWspaamUrly5WJ98QcQESpXrnxVTzqaAJRSxV5xv/hfcrXn6RMJYPamw8zckIgOfa2UUr/yiQQwc30iT32+iXsmrOHQqfNOh6OU8iGnT5/mvffeu+r9evTowenTpz0Q0a98IgGMGxLDP3s3YsOh03R7cxnvL9tLemaW02EppXzA5RJARkbGH+43b948KlSo4KmwAB9JAP5+wpC2kSx6ugPt64Uyav5Oer+7kk0Jns2uSik1cuRI9u7dS7NmzYiJiaF9+/b07t2bhg0bAtC3b19atmxJo0aNGDt27C/7RUZGcvLkSQ4cOECDBg146KGHaNSoEd26dePChQtuiU2KUrl4dHS0ccdYQN9sPcrzs7dy/OxFhrSJZPjN9SkTpC1ilSqOduzYQYMGDQD455xtbD/8s1uP37BGOZ6/pdFl1x84cIBevXqxdetWli5dSs+ePdm6desvTTWTk5OpVKkSFy5cICYmhmXLllG5cuVfxj47d+4cdevWJS4ujmbNmtGvXz969+7NoEGDrni+l4jIOmNMdM5tfeIJIKfYxtVY9HRHBl1fi49XHaDr68v4dvsxp8NSSvmAVq1a/aad/ttvv811111H69atSUhIYM+ePb/bJyoqimbNmgHQsmVLDhw44JZY8nTbKyKxwFuAPzDOGDMqx/qngQeBDOAEcL8x5qBr3RDgOdem/zbGfOxa3hKYCJQE5gFPmEJ8HCkXHMi/+jamb/Mwnp2xmQcnxdGjSTVeuKURVcoFF1YYSqlC9Ed36oWldOnSv7xeunQp3377LatWraJUqVJ06tQp13b8QUFBv7z29/d3WxHQFZ8ARMQfGA10BxoCA0WkYY7NNgDRxpimwHTgFde+lYDngeuBVsDzIlLRtc8Y4CGgnusntsBnkw8ta1Xk6z+1Z8TN9fl2x3Fuen0Zn64+SFZW0SkaU0p5r7Jly3L27Nlc1505c4aKFStSqlQpdu7cyerVqws1trwUAbUC4o0x+4wxacBUoE/2DYwxS4wxl9pXrgbCXa9vBhYZY5KNMT8Bi4BYEakOlDPGrHbd9U8C+rrhfPKlRIAfj3euy4InO9C4Rnme+2ord36wit3Hcv+lKaVUXlWuXJl27drRuHFjRowY8Zt1sbGxZGRk0KBBA0aOHEnr1q0LNba8FAGFAQnZ3idi7+gv5wFg/h/sG+b6Scxl+e+IyFBgKEDNmjXzEG7+RYWUZspD1zN9XSIvzdtBz7eX82jHOjzWuS7Bgf4e/WylVPE1ZcqUXJcHBQUxf/78XNddKucPCQlh69atvywfPny42+JyayWwiAwCooFX3XVMY8xYY0y0MSY6NPR3M5q5nYhwZ3QE3z3dkV5Na/D24nh6vLWcVXtPefyzlVKqMOUlASQBEdneh7uW/YaIdAH+D+htjLl4hX2T+LWY6LLHdFLlMkG80b8Zk+5vRXpWFgM/XM1fp2/i9Pk0p0NTSim3yEsCWAvUE5EoESkBDABmZ99ARJoDH2Av/sezrVoAdBORiq7K327AAmPMEeBnEWktdvSie4BZbjgft+twTSgLn+zIwx1r8+X6JLq8voxZG5N0XCGlVJF3xQRgjMkAhmEv5juAacaYbSLyooj0dm32KlAG+EJENorIbNe+ycC/sElkLfCiaxnAY8A4IB7Yy6/1Bl6nZAl/nu3egNnD2hFWoSRPTN3IvR+tJSFZxxVSShVdPtkTuCAyswyTVh3g1QW7MAae6lqP+9tFEeDvk33qlPJ6ufWMLc60J7AH+fsJ97WLYtHTHWlbpzL/mbeTPqNXsjlRxxVSShUtmgDyKaxCScYNiea9u1tw/OxF+o5eyYtztnM2Nd3p0JRSXiS/w0EDvPnmm5w/77miZk0ABSAi9GhSnW+f7sjAVjWZsHI/nV9bxvR1idqTWCkFeHcC0CEw3aB8yUBeurUJd0ZH8MLsbQz/YhOfrD7IP3s3olmEZ8fzVkp5t+zDQXft2pUqVaowbdo0Ll68yK233so///lPUlJS6NevH4mJiWRmZvL3v/+dY8eOcfjwYTp37kxISAhLlixxe2yaANyoWUQFZjzalhkbkhg1fyd9R6/kzpbhjIitT5WyOsCcUo6bPxKObnHvMas1ge6jLrt61KhRbN26lY0bN7Jw4UKmT5/OmjVrMMbQu3dvvv/+e06cOEGNGjWYO3cuYMcIKl++PK+//jpLliwhJCTEvTG7aBGQm/n5CXe0DGfJ8I483KE2X21M4sbXlvHh9/tIy9BZyJTyZQsXLmThwoU0b96cFi1asHPnTvbs2UOTJk1YtGgRzzzzDMuXL6d8+fKFEo8+AXhI2eBAnu3RgP4xEbz49XZemreDz9Ye4h+9GtKpfhWnw1PKN/3BnXphMMbw7LPP8vDDD/9u3fr165k3bx7PPfccN910E//4xz88Ho8+AXhY7dAyTLyvFRPujSYry3DvR2t58OO1HDiZ4nRoSqlCkH046JtvvpkJEyZw7tw5AJKSkjh+/DiHDx+mVKlSDBo0iBEjRrB+/frf7esJ+gRQSG68tirt6obw0coDvPPdHrq98T0PtI9iWOe6lNbpKJUqtrIPB929e3fuuusu2rRpA0CZMmX49NNPiY+PZ8SIEfj5+REYGMiYMWMAGDp0KLGxsdSoUcMjlcDaE9gBx35O5b/zdzJjQxJVywUxsvu19G0Whh0WSSnlTtoTWHsCe5Wq5YJ5vX8zvny0LVXKBvPU55u44/1VbEk843RoSikfognAQS1rVWTW4+145famHDiZQu/RK3h2xmZOnbt45Z2VUqqANAE4zM9P6BcTweLhnbi/XRRfxCXS6bWlTFixn/RMbTaqlDsUpaLugrja89QE4CXKlwzk770a8s2T7WkWUYEXv95Oj7eWs2LPSadDU6pICw4O5tSpU8U+CRhjOHXqFMHBee90qpXAXsgYw6Ltx/j33B0cSj7PzY2q8lzPhkRUKuV0aEoVOenp6SQmJpKamup0KB4XHBxMeHg4gYGBv1l+uUpgTQBeLDU9k/Er9vPu4ngyjeHhDrV5tFMdSpXQZqNKqbzTVkBFUHCgP493rsvi4R3p3rga7yyO56b/LWPqmkNczMh0OjylVBGnCaAIqF6+JG8NaM4Xj7QhtGwQI2dsoeMrSxm3fB8pFzOcDk8pVURpEVARY4xh+Z6TjFm6l1X7TlG+ZCBD2kZyb9tIKpUu4XR4SikvpHUAxdD6Qz/x/tK9LNx+jOBAPwbE1OShDrUJq1DS6dCUUl5EE0AxFn/8LO8v28dXG5IA6NMsjEc61qZe1bIOR6aU8gYFqgQWkVgR2SUi8SIyMpf1HURkvYhkiMgd2ZZ3FpGN2X5SRaSva91EEdmfbV2zgpygL6tbpSyv3Xkdy/7amcFtajFvyxG6vvE9QyfFseHQT06Hp5TyUld8AhARf2A30BVIBNYCA40x27NtEwmUA4YDs40x03M5TiUgHgg3xpwXkYnA17ltezn6BJA3ySlpTPzhAB//cIAzF9JpXbsSj3aqS4d6ITrgnFI+qCBPAK2AeGPMPmNMGjAV6JN9A2PMAWPMZuCPxi64A5hvjPHcDMcKgEqlS/B012v4YeSNPNezAftPpjBkwhp6vbOCrzcfJlMnrFdKkbcEEAYkZHuf6Fp2tQYAn+VY9pKIbBaRN0QkKLedRGSoiMSJSNyJEyfy8bG+q3RQAA+2r833f+3MK7c35UJaJsOmbOCm/y3lM+1LoJTPK5R+ACJSHWgCLMi2+FngWiAGqAQ8k9u+xpixxphoY0x0aGiox2MtjoIC/OkXE8Gipzsy5u4WdrrKGVto/98lfLBsL2dT050OUSnlgLwkgCQgItv7cNeyq9EPmGmM+eVKY4w5YqyLwEfYoiblQf5+Qvcm1Zk9rB2fPnA99aqW4eX5O2k3ajGvLdjFSR2GWimfkpdBZdYC9UQkCnvhHwDcdZWfMxB7x/8LEalujDkitlayL7D1Ko+p8klEuKFeCDfUC2FTwmneX7aX0UvjGbdiH/2jI3iwfW0deE4pH5CnfgAi0gN4E/AHJhhjXhKRF4E4Y8xsEYkBZgIVgVTgqDGmkWvfSGAlEGGMycp2zMVAKCDARuARY8y5P4pDWwF5Tvzxc4z9fi8zNySRZaB742r0bRZGh2tCKRGgI4YoVZRpRzCVJ0fOXGDc8v18uT6R0+fTKRccQPfG1endrAata1fG30+bkSpV1GgCUFclLSOLlfEnmb3pMAu3HSUlLZOQMkH0bFKN3s1q0DyiIn6aDJQqEjQBqHxLTc9k8c7jzNl0mO92HictI4uwCiXpdV11bmlag0Y1ymkHM6W8mCYA5RZnU9NZtP0YczYdZvmek2RkGWqHluaWpjXo3awGdULLOB2iUioHTQDK7ZJT0vhm61HmbDrM6v2nMAYaVi/HLdfV4JbrqhNeUVsSKeUNNAEojzr2cypzNx9h9qbDbEw4DUCLmhXofV0NejStTpWyeZ+oWinlXpoAVKFJSD7P7E2HmbPpMDuPnsVPoE2dytzStAaxjatRoZROXKNUYdIEoByx59hZ5mw6zOxNhzlw6jyB/kKHeqHccl0NujasSukgneBeKU/TBKAcZYxha9LPzNlsnwyOnEklONCPPteFMbhNLRqHlXc6RKWKLU0AymtkZRnWHfqJL9clMmvjYS6kZ9KiZgXuaRNJ9ybVCArwdzpEpYoVTQDKK525kM70dYl8uvog+0+mEFKmBP1jIrj7+lrU0LmNlXILTQDKq2VlGVbEn2TSqoMs3nkMgC4NqjKkbSRt61TWjmZKFcDlEoDWwCmv4OcndLgmlA7XhJKQfJ4paw4xdc0hFm4/Rp3Q0gxuXYvbWoZTLjjQ6VCVKjb0CUB5rdT0TOZuPsKk1QfZlHCaUiX8ubV5GPe0iaR+tbJOh6dUkaFFQKpI25x4mkmrDjJn02EuZmTRKqoS97Spxc2NqhHor8NVK/VHNAGoYuGnlDSmxSXw6Y8HSUi+QJWyQQxsVZO7rq9J1XLa21ip3GgCUMVKZpZh2e7jTFp1kGW7T+Avws2NqnFPm1q0iqqklcZKZaOVwKpY8fcTbry2KjdeW5WDp1L4dPVBpsUlMnfLEepXLcugNrW4rXmY9jRW6g/oE4AqNi6kZTJn02EmrT7A1qSfKRMUwO0twhjUuhb1qmqlsfJdWgSkfIYxhg0Jp/lk1UHmbj5CWmYWzWtWoH90BL2uq0EZfSpQPkYTgPJJp85dZOaGJD5fm8Ce4+coVcKfnk2q0z8mgpa1KmpdgfIJmgCUT7v0VDBtbQJzNh0mJS2TOqGl6R8TwW0twgkpE+R0iEp5TIESgIjEAm8B/sA4Y8yoHOs7AG8CTYEBxpjp2dZlAltcbw8ZY3q7lkcBU4HKwDpgsDEm7Y/i0ASg3CHlYgZzNx/h87gE1h38iQA/4aYGVegfE0GHeqEEaL8CVczkOwGIiD+wG+gKJAJrgYHGmO3ZtokEygHDgdk5EsA5Y8zvJooVkWnADGPMVBF5H9hkjBnzR7FoAlDuFn/8LNPiEpmxPpGT59KoWi6IO1qG0y86glqVSzsdnlJuUZAE0AZ4wRhzs+v9swDGmJdz2XYi8PWVEoDYgtcTQDVjTEbOz7gcTQDKU9Izs/hux3GmxSWwdNdxsgy0qV2Z/jERxDauRnCgDlGtiq6C9AMIAxKyvU8Err+Kzw4WkTggAxhljPkKW+xz2hiTke2YYZcJfCgwFKBmzZpX8bFK5V2gvx+xjasR27gaR8+kMn1dAtPiEnny842UnRVA32Zh9I+J0IlrVLFSGO3hahljkkSkNrBYRLYAZ/K6szFmLDAW7BOAh2JU6hfVygcz7MZ6PNapLqv3n2La2gSmxSXwyeqDNKxejv4xEfRtFkb5UjoyqSra8pIAkoCIbO/DXcvyxBiT5Pp3n4gsBZoDXwIVRCTA9RRwVcdUqjD4+Qlt64TQtk4I/7yQzuyNSXwel8Dzs7fx0rwdxDaqxoCYCFrXroyfnzYnVUVPXhLAWqCeq9VOEjAAuCsvBxeRisB5Y8xFEQkB2gGvGGOMiCwB7sC2BBoCzMrPCShVGMqXDGRwm0gGt4lk2+EzTFubwMwNSczedJiISiUZEFOTga1qUql0CadDVSrP8toMtAe2mac/MMEY85KIvAjEGWNmi0gMMBOoCKQCR40xjUSkLfABkAX4AW8aY8a7jlkbe/GvBGwABhljLv5RHFoJrLxJanomC7Yd5fO1Cfyw9xTBgX7c3iKcB26Ionbo7xq+KeUY7QimlAftOXaWccv3M3NDEulZWdx0bVUeah+lI5Mqr6AJQKlCcOLsRT5ZfZBPVx8kOSWNpuHlebB9bXo0rqYdzJRjNAEoVYhS0zP5cn0i45fvZ9/JFMIqlOS+dpH0j4mgrM5rrAqZJgClHJCVZVi88zgfLt/Hj/uTKRsUwIBWEdzbLoqwCiWdDk/5CE0ASjlsc+Jpxi3fz9wtRwDo2aQ6D7aPoml4BYcjU8WdJgClvETS6QtMXLmfqWsSOHsxg1ZRlXiofW1uuraK9idQHqEJQCkvczY1nc/XJvDRygMknb5A7ZDS3H9DFLe3CKdkCR17SLmPJgClvFRGZhbztx5l3PJ9bEo8Q8VSgQxuXYvBbSIJLavzFKiC0wSglJczxrD2wE98uHwf3+44RqC/H7c2C+PB9lE6p7EqkIKMBqqUKgQiQquoSrSKqsS+E+eYsHI/09cl8nlcAp3qh/JQ+9q0rVNZO5Ypt9EnAKW8WHJKGpNXH+TjVQc5ee4iLWtV5C/drqFtnRCnQ1NFiBYBKVWEXczIZPq6RN5dHM+RM6m0q1uZ4d3q07xmRadDU0WAJgClioHU9Ewm/3iI95bEcyoljS4NqvB01/o0rFHO6dCUF9MEoFQxknIxg4k/HOCDZXv5OTWDXk2r81TXa6ijo5CqXGgCUKoYOnMhnXHL9zF+xX5S0zO5vUU4f76pHhGVSjkdmvIimgCUKsZOnbvImKV7mbT6IMYYBraqybDOdalSLtjp0JQX0ASglA84eiaVdxbv4fO1Cfj7CUPaRvJIxzo6U5mP0wSglA85dOo8b363m682JFGqRAD33xDFg+2jKKdDUfskTQBK+aD442d5fdFu5m05SoVSgTzcoQ5D2taiVAntA+pLNAEo5cO2Jp3hfwt3sWTXCULKBDGscx0GXl+ToAAddM4XaAJQSrHuYDKvLtjF6n3JhFUoyZ9vqsvtLcJ1uspi7nIJQH/rSvmQlrUq8dlDrZn84PWElg3imS+30OX1ZczamERWVtG5GVTukacEICKxIrJLROJFZGQu6zuIyHoRyRCRO7ItbyYiq0Rkm4hsFpH+2dZNFJH9IrLR9dPMPaeklPojIkK7uiHMfKwt4+6JJjjQnyembqT7W8tZsO0oRalUQBXMFROAiPgDo4HuQENgoIg0zLHZIeBeYEqO5eeBe4wxjYBY4E0RyT7/3QhjTDPXz8Z8noNSKh9EhC4NqzLvz+15Z2Bz0jOzePiTddz63g+sPZDsdHiqEOTlCaAVEG+M2WeMSQOmAn2yb2CMOWCM2Qxk5Vi+2xizx/X6MHAcCHVL5Eopt/DzE265rgYLn+rAK7c35eiZVO58fxVDJ8Wx98Q5p8NTHpSXBBAGJGR7n+hadlVEpBVQAtibbfFLrqKhN0Qk16mPRGSoiMSJSNyJEyeu9mOVUnkU4O9Hv5gIlgzvxIib6/PD3lN0e+N7nvtqCyfOXnQ6POUBhVIJLCLVgU+A+4wxl54SngWuBWKASsAzue1rjBlrjIk2xkSHhurDg1KeVrKEP493rsvSEZ24+/qaTF2TQKdXl/DOd3u4kJbpdHjKjfKSAJKAiGzvw13L8kREygFzgf8zxqy+tNwYc8RYF4GPsEVNSikvEVImiBf7NGbhUx1oXy+U/y3aTafXljBtbQKZ2mKoWMhLAlgL1BORKBEpAQwAZufl4K7tZwKTjDHTc6yr7vpXgL7A1qsJXClVOGqHluH9wS2Z/kgbalQoyV+/3EyPt5azZNdxbTFUxF0xARhjMoBhwAJgBzDNGLNNRF4Ukd4AIhIjIonAncAHIrLNtXs/oANwby7NPSeLyBZgCxAC/NutZ6aUcqvoyErMeLQt793dgtSMTO77aC2Dxv/I1qQzToem8kl7AiulrlpaRhaTfzzI29/t4fSFdG5tFsZfbq5PWIWSToemcqFDQSil3O7MhXTGLN3LhJX7Abi/XRSPda6jo456GU0ASimPSTp9gf8t3MXMDUlUKBnIn26sx6DWtSgRoKPNeAMdC0gp5TFhFUryer9mzBl2A41qlOfFr7fT9Y1lzN18RCuKvZgmAKWU2zQOK88nD7Ri4n0xBAf48/iU9dw25gfidGgJr6QJQCnlViJCp/pVmPdEe165vSmHT1/gjvdX8fAnOrSEt9E6AKWUR11Iy2T8in2MWbqX1Iws7mpVkye61COkTK6jvygP0DoApZQjSpbwZ9iN9Vj2187c1aomU9YcotOrSxm3fB/pmVlXPoDyGE0ASqlCEVImiH/1tUNLxERW5N9zd9DjreX8sPek06H5LE0ASqlCVSe0DBPujWHcPdGkZmRy14c/8viU9Rw5c8Hp0HyOJgClVKG7NBnNoqc68lSXa/h2+zFufG0Z7y2N52KGjjhaWDQBKKUcExzozxNd6vHt0x1pXy+EV77ZRfc3l7Nst879URg0ASilHBdRqRRj74lm4n0xGGDIhDUMnRRHQvJ5p0Mr1jQBKKW8Rqf6VfjmyfY8E3stK+JP0uX1Zbz17R5S07VYyBM0ASilvEpQgD+PdqrDd3/pSNeGVXnj2910fWMZi7Yf02El3EwTgFLKK1UvX5J372rBlAevJzjAn4cmxXH/xLUcOJnidGjFhiYApZRXa1s3hHlPtOe5ng1Ye+Anur3xPa8t2MX5tAynQyvyNAEopbxeoL8fD7avzeLhHenVtDrvLomny/+WMX+LjjZaEJoAlFJFRpWywbzevxlfPNKG8qVK8Ojk9Qwev4b442edDq1I0gSglCpyYiIrMWdYO17s04jNiaeJfXM5L8/bwbmLWix0NTQBKKWKpAB/P+5pE8mS4Z24o2U4Y5fv48bXljJrY5IWC+WRJgClVJFWuUwQo25vyszH2lGtfDBPTN1I/7Gr2Xn0Z6dD83p5SgAiEisiu0QkXkRG5rK+g4isF5EMEbkjx7ohIrLH9TMk2/KWIrLFdcy3RUQKfjpKKV/VLKICXz3WjlG3NWHPsbP0fHsFo+bv1LGF/sAVE4CI+AOjge5AQ2CgiDTMsdkh4F5gSo59KwHPA9cDrYDnRaSia/UY4CGgnusnNt9noZRSgJ+fMKBVTZYM78SdLcN5f9le+ry7ku2H9WkgN3l5AmgFxBtj9hlj0oCpQJ/sGxhjDhhjNgM5Z3e4GVhkjEk2xvwELAJiRaQ6UM4Ys9rYwrpJQN+CnoxSSgFUKFWCUbc35aN7Y0hOSaPP6BWMXhJPhk5A8xt5SQBhQEK294muZXlxuX3DXK+veEwRGSoicSISd+KEjhColMq7ztdWYcGTHYhtXJ1XF+zijvdXsU/nJf6F11cCG2PGGmOijTHRoaGhToejlCpiKpYuwTsDm/PuXc05cCqFHm8vZ+LK/WRlaUuhvCSAJCAi2/tw17K8uNy+Sa7X+TmmUkpdtV5Na7DwyQ60qV2ZF+ZsZ9D4H0k67duzkOUlAawF6olIlIiUAAYAs/N4/AVANxGp6Kr87QYsMMYcAX4Wkdau1j/3ALPyEb9SSuVZlXLBTLg3hlG3NWFTwmli3/ieL+ISfLbfwBUTgDEmAxiGvZjvAKYZY7aJyIsi0htARGJEJBG4E/hARLa59k0G/oVNImuBF13LAB4DxgHxwF5gvlvPTCmlciFiWwp982QHGtYox4jpm3lo0jpOnL3odGiFTopS5ouOjjZxcXFOh6GUKiaysgwTVu7nlQW7KBMUwEt9G9O9SXWnw3I7EVlnjInOudzrK4GVUspT/PyEB9vXZt6fbyC8YkkenbyeJ6du4Mz5dKdDKxSaAJRSPq9ulbJ8+WhbnupyDV9vPkK3N5f5xMT0mgCUUgo758ATXeox87F2lAsOZMiENfzfzC2kFOMRRjUBKKVUNk3CyzPnTzcwtENtpqw5RPe3lrP2QPKVdyyCNAEopVQOwYH+/K1HAz4f2gaAfh+s4uV5O0hNL14Dy2kCUEqpy2gVVYn5T7RnYKuafPD9Pnq/u4KtSWecDsttNAEopdQfKB0UwH9ubcLE+2I4cyGdvqNX8vZ3e4rFwHKaAJRSKg861bcDy/VsWp3XF+3m9jE/FPm5iDUBKKVUHlUoVYK3BjTnvbtbcCj5PD3fXsH7y/YW2UlnNAEopdRV6tGkOgue6kCHa0IZNX8n3d74nvlbjhS5MYU0ASilVD5UKRvMh/dE8/H9rQgK8OPRyevp98EqNiWcdjq0PNMEoJRSBdDxmlDm/bk9/7m1CftPptBn9Eqe+nwjh4vAUNM6GJxSSrnJ2dR0xizdy7gV+xFgaIfaPNyxDmWCAhyNSweDU0opDysbHMhfY69l8V86Etu4Gu8sjqfTq0uZuuYQmV44A5kmAKWUcitd/V4AABhcSURBVLPwiqV4a0BzZj7WllqVSzFyxhZ6vr2cFXtOOh3ab2gCUEopD2lesyLTH2nD6LtacO5iBoPG/8j9E9d6Tf8BTQBKKZVfxkDWH/cIFhF6Nq3Ot0935Nnu17J2fzI3v7mcf8zayqlzzs5CpglAKaXyI+UkTLgZPu4FWVfuCBYc6M/DHeuwdEQn7mpVk8k/HqLTq0v5wMGOZJoAlFLqav10AMZ3g8Q4OLgS4ibkedfKZYL4V9/GLHiyPTFRlXh5/k66vL6MuZsLvyOZJgCllJWZDl89DktedjoS73Zks734nz8F982H2p3gu3/B2WNXdZi6Vcoy4d4YPnmgFaVLBPD4lPXc8f4qNhz6ySNh50YTgFLKlmN/9Rhs/BSWjYJ9y5yOyDvtWwYf9QC/QHhgIdS8Hnr8DzIuwMLn8nXI9vVCmfvn9oy6rQkHT53n1vd+4ImpG0gqhI5keUoAIhIrIrtEJF5ERuayPkhEPnet/1FEIl3L7xaRjdl+skSkmWvdUtcxL62r4s4TU0rlkTGw4G+wZRp0fAYq1YHZf4K0FKcj8y5bZ8DkO6B8uL34h9a3y0PqQrsn7f/f/u/zdWh/P2FAq5osHdGJYZ3r8s3Wo9z42lJe+WYnZ1M9N0H9FROAiPgDo4HuQENgoIg0zLHZA8BPxpi6wBvAfwGMMZONMc2MMc2AwcB+Y8zGbPvdfWm9Mea4G85HKXW1lr8GP46B1o9Bp2ehz7tw+qAt1lDW6vdh+v0Q1hLunw/lw367vv3TUDES5v4FMtLy/TFlggIYfnN9Fg/vRPfG1Xhv6V46v7aUKT8e8sj8A3l5AmgFxBtj9hlj0oCpQJ8c2/QBPna9ng7cJCKSY5uBrn2VUt5i7XhY/G9oOgC6vQQiUKsttBoKP74Ph1Y7HaGzjIFvX4BvnoFre8LgmVCy4u+3CywJPV6Dk7th1TsF/tiwCiV5c0BzZj3ejqiQ0vxt5ha2H/m5wMfNKS8JIAxIyPY+0bUs122MMRnAGaByjm36A5/lWPaRq/jn77kkDABEZKiIxIlI3IkTJ/IQrlIqT7bNtHes9W62d/1+2S4HNz0P5SNg1uOQ7v2DmnlEZrqtF1nxBrS8D/pNshf6y6nXFRr0hmWv2lZCbnBdRAWmPdyGGY+1pWl4BbccM7tCqQQWkeuB88aYrdkW322MaQK0d/0Mzm1fY8xYY0y0MSY6NDS0EKJVygfsXQxfPgQ1W8OdE8E/8Lfrg8pA77fhVDwsHeVIiI5KS4Gpd8GmKdDpb9DrDfDzv/J+sS+D+MH831WV5puI0KJmLk8dbpCXBJAERGR7H+5alus2IhIAlAdOZVs/gBx3/8aYJNe/Z4Ep2KIm5QuMgT2LYO5wOLzxytsr90pcB1MH2UrMgVOhRKnct6vTGVrcAz+8DUnrCzdGJ6Wcgo9vgfhvodeb0OkZWzSWF+XDofOzsHs+7Jzr2TjdIC8JYC1QT0SiRKQE9mI+O8c2s4Ehrtd3AIuNq0eDiPgB/chW/i8iASIS4nodCPQCtqKKt6ws2DEHxna0rSnWjoMPb4SFf4e0805H5xtO7LL/92VCYdCXUPIKxQrd/g1lqsKsYQWq3CwyfjoIE7rBsW3Q7xOIvu/qj3H9I1ClIcx/xutbUl0xAbjK9IcBC4AdwDRjzDYReVFEers2Gw9UFpF44Gkg+/NPByDBGLMv27IgYIGIbAY2Yp8gPizw2SjvlJUJW6bDmLbw+SC4eBb6jIYR8dB8kL3DHNNW25572ukE+ORW8AuwlZllq115n+Dy9i74+DZY8brnY3TS0S0wviuknIDBX0GDXvk7jn8g9HwdziTAslfcG6Ob+caEMJs+h9TTEBYN1ZpAQAn3B6d+LzMdNn8Oy1+H5L0Q2gA6DIeGfcE/2wQZ+5fDnCfsNs0HQdd/QalKzsVdHKWcsuPWnDsO9821fwdX48uHYNsMGLoMqjX2TIxO2r/clvkHlbVPRlUaFPyYXz0Om6fCIyvcc7wCuNyEML6RACb3gz0L7Gv/ElD9OpsMwqNtu96KkXkv41NXlp4KGz6BlW/Zu6Dq10GHEVC/529bmvxmnwv2bmnlW1CqMvR4xSYK/b0U3MWz8HFvOL7d3vnXanv1xzifDKNbQbkwePC73ybwom7bVzDjIahU2178y4e757gpp+DdlrY46N65jn6XfTsBAJxJgsS1kBRnK8EOb7DdtwFKhbiSQTSEt4QaLa5cNqp+Ly0F4j6CH96Bc0ch4np74a/bJe9f/iObbS/UIxuhfg/btjpnpxuVdxkXYfKdcGAFDJgM9bvn/1jbvoIvhkCXF+CGp9wVobPWfAjzRtjv6sDP3P/kue5jmPNn6Ps+NBvo3mNfBU0AOWVm2DuipDg7ol9iHJzc9ev6kGt+fUoIj4YqjYrXXY87pZ6xf0ir37MDZEV1sBf+yPb5u+vJzLA9Uxe/ZMuru74ALe+//NODyl1WJky/D7bPct8F6PPBsHsBPLoSQuoV/HhOMQYW/wuW/8/eaNwx4Y/b+OdXVpYtekveB3+Ky70TWSHQBJAXqWdsc7fsSeG8awq3gJJQo5ktMgqPhvAY+zjsy0UU55Nh9Rj48QO4eAbqdYP2w+0AWe6QvB++fhL2LYWabeCWtyH0Gvccu7gzxv7frZtoe/i2Heae4549ZouCQuvbkTDz0jbe22Rm2DqnjZ9CiyG2wtaTN3dHt8AHHaDlvbY/gQM0AeSHMXZMlMQ4SFpni5CObIZM1yw+Zar9Wo8QHm2LjoLKFF58Tjl7DFa9a4cRSE+xvR/b/8UmSHczBjZOsYOVpZ+HDn+Fdk9oRf6VfPcvO8bPDU9Dl+fde+xNU2HmwxD7X2j9iHuP7Wlp5+GLe22dYMeR0Glk4dzEffOsvVl68DtbzFzINAG4S0YaHNti6xEuPSkk77XrAkvBXZ/bIpDi6EyiraRdPwky06DxHXYQrMJo4XDuuG1XvW2GrVTr/Y5Nuur3Vr0HC561d7e3vOX+C5wxMKWfrVd49AeoFOXe43vK+WQbd9I6W7cU80DhfXbqz/bJqUwVeGhJoT85aQLwpPPJ9ku18Dn4+TDcN+/qm9l5s+R9djyUjZ8BBq4baCsBK9cp/Fh2zbfj1/x82Ha4ufE533jqyqtLd+cNboE7P/bcheZMErzX2rbwGjLH+4tCTx+CT26z/94x3v7/FLatM2ydTPdX4fqhhfrRmgAKw5lEO1NQVgY8sAgq1nI6ooI5vtN2/tnyhZ0Ao8U9tvilQsSV9/Wk1J/huxdh7YdQvqYtV63XxdmYvMHuBfDZQIhsB3dPh4Agz37euom2LL3Xm/nrMVtYjm2DT2+3RYgDp+avGaw7GAOf3mZLDYatzVtHPDe5XALQZhXuVD7ctiPOSLW/6JRTV97HG52Mh2n32Du8HV9Dm8fhyc3Q8zXnL/4AweVsLPcvgMBgmHw7zBhadP+/3eHgKvs7q9YEBkzx/MUfbBFTVAc7lMeZRM9/Xn4cWAETugMC933j3MUf7FNSj9ds09wF/+dcHNloAnC3Kg1g4Of2D2JKP68fC+R3jmyy3eH3LrG9dp/cYseDKcS7lTyr2dr2suz4jH28Hh0Dm6fZOy1fcnQrTOn/6w1IUNnC+VwR2zLLZMLXT3nf//v2WbbYp2w1O4NX1ZzzWDmgch1bfLp1um3d5jBNAJ5Qqw3cPh4Or7ctDjI9N6WbWyXG2VEQS5SGh5fZ8vXSOad18DIBQdD5b/Dw91AxyvbonHyHLev1Bcn77dNmidJ2/JrSIYX7+ZWi7NwBexbaYT+8waU77Gn32DqK+7/xjifXS254yn5X5/7FxuogTQCe0qAX9Pyf/cOY86T33R3ldHAVTOprO6rcN892iy9Kqja0d3ndX7HnMrq1ncYvK9PpyDzn7DH4pK9tkTV4pnMXuVZDIaK1baV19pgzMVxyfCd8eJNtphz9AAyZ7X3jSgUG2yLMU/F2IEQHaQLwpOj7bVvjjZ/aXofeat8yexdZtqrt3FOhptMR5Y+fP1z/MDy+2pb1fvOMrZTfvdCOh1OcXDhtKzbPnbAVvlWudS4WPz87o1j6BZj7tDM3O8bY3uhjO8LZw7ayt9frnund6w51u9ixrr5/zT7FOUQTgKd1Gmkry5b/D34c63Q0vxf/ra2rqFAL7p0H5Wo4HVHBVagJd38Bt42Dn/bDlDthVC17Z7joedjzbdFOCOkXbGufEzuh/yfe0R8ipJ4titv5NWz/qnA/+9wJWwcybzjUagePrirYmEeFJfZlO9TJ/L86VkKgzUALQ2YGTBts27DfOREa9XU6ImvXfFtOGlofBs/y/vL+/Eg7Dwk/2tYgB1bYzntZGSD+UKM5RN5gxyyqeX3hVZ4WRGaGnVNh9ze2PXvj252O6FeZGTDuJtsA4vE1hfN92rMIvnrUNg3u+qItjipKY0atGm17uff/1KN9E7QfgNPSztvy2sMbYNAMiGrvbDzbvoIvH4BqTW3LEW8rJ/WUtBRIWFM0E0JWlp2kfdMUW78U86DTEf3esW3wQUdodCvc7sE5ntIv2Ke5NR/YgRpv/xCqNvLc53lKZoYttrpwGh7/0WOdGjUBeIPzyTAhFs4esWXtTk2ssXma7S0aHmOLSoLLOxOHN/D2hJBx0c5QlXICNky2nd86/c3OU+utlo6CpS/bcnhPFMUc2wZfPmhH8239mG2FFBjs/s8pLId+tNNQtv0zdPNMXaEmAG9xOsFWTJoseHBR4Ve4rv/EjrcfeYP9A9VhFH4rLSVHkdE69yYEY+zsdCkn7UX93HHXBf4kpGR7fe64/ffimd/u3+ph6P5f7x56ISMNxnaCC8nw2Gr3za2RlWXv+Bc9b4/Z9z1bmVoczP6THfTw4eUe6a+gCcCbHNtunwTKVLFNFwur+GXteNtKo86N0H8ylChVOJ9blOU1IYTWtxe8lBO2UjIll59Ly7Ny6xci9ntQOvS3P2Uuva5iK+irX+fdF/9LDm+wle7N7rIthArq7FFb1r93sR2/v/c7hd/nwZPOJ8M7LX8dZtvNv2NNAN7mwEo7QXf1pnDPbM9fjC+NEHlNrB0krCg/MjvpcgkhN/5Bv7+Ilw5xLbv0uop9X6py8ZtwaNHzsPJN20ehzo35P87OuTBrmC33j/0PtLyvaCTBq7X+E5g9DPq8B83vduuhNQF4o+2z7RR79brZO3JPXQBWvAHfvmDH7b99vI6l706XEsJPB+zUomWq/Hr3HlS2eF6o8ir9Arzf3tZjPLbq6osb01Jsj951H9nGCrePL94TAmVlwUextoPYsDi3lgwUaDA4EYkVkV0iEi8iI3NZHyQin7vW/ygika7lkSJyQUQ2un7ez7ZPSxHZ4trnbREf/Etp2NsODrX7G/j6Cfe3BTbGVsh9+wI0uRPu+Egv/u5WorS9u42+3/4+a7a2470El/Ptiz/YTlh93oUzCfDdP69u38MbbWuidRPtCLQPfle8L/5gm6/2fN22CLra/6/8fuSVNhARf2A00B1oCAwUkZy1FA8APxlj6gJvAP/Ntm6vMaaZ6yf79EFjgIeAeq6f2PyfRhEW84Cd5WrDp7DkJfcd1xj7JVr6MjS7G279oPgVMSjvV7O1nbdhzVg4+MOVt8/KghVvwrgu9gngnlm2fb+v3LhUawytH7WTySes9fjH5eUJoBUQb4zZZ4xJA6YCfXJs0wf42PV6OnDTH93Ri0h1oJwxZrWxZVCTAC/pHeWAzn+D5oPh+1dtd/aCMsZ2Llnxhi0v7f1u0Zy7VRUPN/3d9jSf9bjtD3M5Z5JgUm/49nnbfPTRlVC7Y+HF6S06jYSy1WHuU7afgAflJQGEAQnZ3ie6luW6jTEmAzgDXOoGGCUiG0RkmYi0z7Z99gHEczum7xCxk2pcEwvzRti6gfzKyrKjDK5+D65/1E6WUpR6Rqrip0Rp22oneR8s/U/u22z7Csa0haT10Gc09JvkO50TcwoqC91H2cnk147z6Ed5+spwBKhpjGkOPA1MEZFyV3MAERkqInEiEnfixAmPBOkV/ANsGX14jO3kcmDF1R8jKxPm/AnixkO7J+1YI75eDq28Q+2O0PJeO/RB4rpfl188C189bhtDVK4DjyyH5oP0e9ugt+3jsPjf8PMRj31MXhJAEpB9nNlw17JctxGRAKA8cMoYc9EYcwrAGLMO2Atc49o+/ArHxLXfWGNMtDEmOjQ0NA/hFmElXJPKV6wFn91lezzmVWaG7d274VM7AmmXF/SPSHmXri/aoo1Zj9uWQYlxtpXQpinQYYSd4c2Jeaa9kQj0eNUO9b3gbx77mLwkgLVAPRGJEpESwAAgZxnFbGCI6/UdwGJjjBGRUFclMiJSG1vZu88YcwT4WURau+oK7gFmueF8ir5SlezYPCVK2eF+TydceZ+MNDvZ9JYv4KZ/QOdn9eKvvE9weVvUeWKH7QMzvpt9ar13rp18yD/Q6Qi9S6Xa0P4vsG2G7QDnAVdMAK4y/WHAAmAHMM0Ys01EXhSR3q7NxgOVRSQeW9RzqaloB2CziGzEVg4/YoxJdq17DBgHxGOfDOa76ZyKvgo1bRJIO2/H6T+ffPltMy7aET13zIabX7ZfGKW81TXd4LqBcHAlNL4NHl3h7Dy93q7dE1CpDswdDumpbj+8dgTzZgdWuHoLN7PN4XL2Fk6/AFPvhr3fee/okErllHERjm2FsJZOR1I07F1s6wUHf2VHDsiHAnUEUw6JvAFu+xAS18L0+3/bJCwtBSbfab8cvd/Vi78qOgKC9OJ/NercCE9uyffF/49oAvB2jfrayqDd8227YGPs5Bef3GYfo28bCy0GOx2lUsqTSpT2yGG1a2hR0OohOxri8tdsRdrBH+DIJtts1FtmF1NKFTmaAIqKG5+Dc0fhh3fAv4SdQq4ozHuqlPJamgCKChHo9ZZtRx3Z3je7yCul3EoTQFHiH2CfBJRSyg20ElgppXyUJgCllPJRmgCUUspHaQJQSikfpQlAKaV8lCYApZTyUZoAlFLKR2kCUEopH1WkhoMWkRPAwXzuHgKcdGM4Tiou51JczgP0XLxVcTmXgp5HLWPM76ZULFIJoCBEJC638bCLouJyLsXlPEDPxVsVl3Px1HloEZBSSvkoTQBKKeWjfCkBjHU6ADcqLudSXM4D9Fy8VXE5F4+ch8/UASillPotX3oCUEoplY0mAKWU8lE+kQBEJFZEdolIvIiMdDqe/BCRCBFZIiLbRWSbiDzhdEwFJSL+IrJBRL52OpaCEJEKIjJdRHaKyA4RaeN0TPkhIk+5vltbReQzEQl2Oqa8EpEJInJcRLZmW1ZJRBaJyB7XvxWdjDGvLnMur7q+X5tFZKaIVHDHZxX7BCAi/sBooDvQEBgoIg2djSpfMoC/GGMaAq2Bx4voeWT3BLDD6SDc4C3gG2PMtcB1FMFzEpEw4M9AtDGmMeAPDHA2qqsyEYjNsWwk8J0xph7wnet9UTCR35/LIqCxMaYpsBt41h0fVOwTANAKiDfG7DPGpAFTgT4Ox3TVjDFHjDHrXa/PYi8yYc5GlX8iEg70BMY5HUtBiEh5oAMwHsAYk2aMOe1sVPkWAJQUkQCgFHDY4XjyzBjzPZCcY3Ef4GPX64+BvoUaVD7ldi7GmIXGmAzX29VAuDs+yxcSQBiQkO19IkX4wgkgIpFAc+BHZyMpkDeBvwJZTgdSQFHACeAjV3HWOBEp7XRQV8sYkwS8BhwCjgBnjDELnY2qwKoaY464Xh8FqjoZjBvdD8x3x4F8IQEUKyJSBvgSeNIY87PT8eSHiPQCjhtj1jkdixsEAC2AMcaY5kAKRaeo4Reu8vE+2IRWAygtIoOcjcp9jG3vXuTbvIvI/2GLgye743i+kACSgIhs78Ndy4ocEQnEXvwnG2NmOB1PAbQDeovIAWyR3I0i8qmzIeVbIpBojLn0NDYdmxCKmi7AfmPMCWNMOjADaOtwTAV1TESqA7j+Pe5wPAUiIvcCvYC7jZs6cPlCAlgL1BORKBEpga3Ymu1wTFdNRARbzrzDGPO60/EUhDHmWWNMuDEmEvv7WGyMKZJ3m8aYo0CCiNR3LboJ2O5gSPl1CGgtIqVc37WbKIKV2TnMBoa4Xg8BZjkYS4GISCy2yLS3Mea8u45b7BOAq+JkGLAA+4WeZozZ5mxU+dIOGIy9W97o+unhdFAKgD8Bk0VkM9AM+I/D8Vw11xPMdGA9sAV7bSgywyiIyGfAKqC+iCSKyAPAKKCriOzBPuGMcjLGvLrMubwLlAUWuf7233fLZ+lQEEop5ZuK/ROAUkqp3GkCUEopH6UJQCmlfJQmAKWU8lGaAJRSykdpAlBKKR+lCUAppXzU/wNDQFEYFvcyDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Dropout, concatenate, Input\n",
    "import keras as K\n",
    "import keras.backend as K2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K2.sum(K2.round(K2.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K2.sum(K2.round(K2.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K2.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K2.sum(K2.round(K2.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K2.sum(K2.round(K2.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K2.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K2.epsilon()))\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# First Half\n",
    "first_half = Input(shape=(199,))\n",
    "x = Dense(150, activation='relu')(first_half)\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Dense(75, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "out_first = Dense(50, activation='relu')(x)\n",
    "# out_first = Dropout(0.2)(x)\n",
    "\n",
    "second_half = Input(shape=(199,))\n",
    "x = Dense(100, activation='relu')(second_half)\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "out_second = Dense(25, activation='relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Dense(50, activation='relu', input_shape=(75,))(x)\n",
    "# out_second = Dropout(0.2)(x)\n",
    "\n",
    "concatenated = concatenate([out_first, out_second])\n",
    "x = Dense(75, activation='relu')(concatenated)\n",
    "# model.add(Dropout(0.2))\n",
    "x = Dense(50, activation='relu')(x)\n",
    "# model.add(Dropout(0.2))\n",
    "x = Dense(20, activation='relu')(x)\n",
    "# model.add(Dropout(0.2))\n",
    "out_final = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = K.Model([first_half, second_half], out_final)\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "opt = K.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc', recall_m, precision_m, f1_m])\n",
    "\n",
    "print('Train...')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "history = model.fit(train_seq_tok_split, train_label, batch_size=batch_size, epochs=epochs, validation_data=(test_seq_tok_split, test_label), callbacks=[es])\n",
    "score, acc, recall, precision, f1 = model.evaluate(test_seq_tok_split, test_label, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "print('Test recall:', recall)\n",
    "print('Test precision:', precision)\n",
    "print('Test F1:', f1)\n",
    "\n",
    "\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29420 samples, validate on 33333 samples\n",
      "Epoch 1/100\n",
      "29420/29420 [==============================] - 3s 103us/step - loss: 0.2024 - acc: 0.9493 - f1_m: 1.8116e-04 - val_loss: 0.0668 - val_acc: 0.9969 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/100\n",
      "29420/29420 [==============================] - 3s 91us/step - loss: 0.1836 - acc: 0.9500 - f1_m: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.9969 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.1761 - acc: 0.9500 - f1_m: 0.0000e+00 - val_loss: 0.1038 - val_acc: 0.9969 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.1658 - acc: 0.9501 - f1_m: 0.0026 - val_loss: 0.0806 - val_acc: 0.9969 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/100\n",
      "29420/29420 [==============================] - 3s 91us/step - loss: 0.1571 - acc: 0.9513 - f1_m: 0.0638 - val_loss: 0.0854 - val_acc: 0.9863 - val_f1_m: 0.0048\n",
      "Epoch 6/100\n",
      "29420/29420 [==============================] - 3s 90us/step - loss: 0.1444 - acc: 0.9524 - f1_m: 0.1606 - val_loss: 0.0357 - val_acc: 0.9941 - val_f1_m: 0.0058\n",
      "Epoch 7/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.1281 - acc: 0.9568 - f1_m: 0.2554 - val_loss: 0.0982 - val_acc: 0.9702 - val_f1_m: 0.0137\n",
      "Epoch 8/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.1105 - acc: 0.9622 - f1_m: 0.3923 - val_loss: 0.0559 - val_acc: 0.9884 - val_f1_m: 0.0070\n",
      "Epoch 9/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0947 - acc: 0.9660 - f1_m: 0.4755 - val_loss: 0.0593 - val_acc: 0.9877 - val_f1_m: 0.0109\n",
      "Epoch 10/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0747 - acc: 0.9723 - f1_m: 0.5946 - val_loss: 0.0456 - val_acc: 0.9890 - val_f1_m: 0.0080\n",
      "Epoch 11/100\n",
      "29420/29420 [==============================] - 3s 90us/step - loss: 0.0649 - acc: 0.9756 - f1_m: 0.6542 - val_loss: 0.0856 - val_acc: 0.9716 - val_f1_m: 0.0126\n",
      "Epoch 12/100\n",
      "29420/29420 [==============================] - 3s 90us/step - loss: 0.0576 - acc: 0.9787 - f1_m: 0.7014 - val_loss: 0.1140 - val_acc: 0.9557 - val_f1_m: 0.0138\n",
      "Epoch 13/100\n",
      "29420/29420 [==============================] - 3s 90us/step - loss: 0.0470 - acc: 0.9831 - f1_m: 0.7694 - val_loss: 0.1143 - val_acc: 0.9609 - val_f1_m: 0.0097\n",
      "Epoch 14/100\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.0411 - acc: 0.9843 - f1_m: 0.7774 - val_loss: 0.0486 - val_acc: 0.9869 - val_f1_m: 0.0054\n",
      "Epoch 15/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0359 - acc: 0.9855 - f1_m: 0.7972 - val_loss: 0.0456 - val_acc: 0.9932 - val_f1_m: 0.0038\n",
      "Epoch 16/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0327 - acc: 0.9876 - f1_m: 0.8000 - val_loss: 0.0628 - val_acc: 0.9862 - val_f1_m: 0.0106\n",
      "Epoch 17/100\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.0294 - acc: 0.9891 - f1_m: 0.8244 - val_loss: 0.0679 - val_acc: 0.9805 - val_f1_m: 0.0064\n",
      "Epoch 18/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0239 - acc: 0.9906 - f1_m: 0.8518 - val_loss: 0.0881 - val_acc: 0.9776 - val_f1_m: 0.0134\n",
      "Epoch 19/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0233 - acc: 0.9911 - f1_m: 0.8575 - val_loss: 0.0751 - val_acc: 0.9823 - val_f1_m: 0.0090\n",
      "Epoch 20/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0254 - acc: 0.9911 - f1_m: 0.8622 - val_loss: 0.0554 - val_acc: 0.9916 - val_f1_m: 0.0070\n",
      "Epoch 21/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0189 - acc: 0.9935 - f1_m: 0.8833 - val_loss: 0.0760 - val_acc: 0.9850 - val_f1_m: 0.0058\n",
      "Epoch 22/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0190 - acc: 0.9929 - f1_m: 0.8743 - val_loss: 0.0923 - val_acc: 0.9799 - val_f1_m: 0.0097\n",
      "Epoch 23/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0179 - acc: 0.9937 - f1_m: 0.9096 - val_loss: 0.1021 - val_acc: 0.9707 - val_f1_m: 0.0137\n",
      "Epoch 24/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0164 - acc: 0.9948 - f1_m: 0.9062 - val_loss: 0.0819 - val_acc: 0.9845 - val_f1_m: 0.0077\n",
      "Epoch 25/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0199 - acc: 0.9928 - f1_m: 0.8869 - val_loss: 0.0679 - val_acc: 0.9820 - val_f1_m: 0.0107\n",
      "Epoch 26/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0138 - acc: 0.9950 - f1_m: 0.9218 - val_loss: 0.0793 - val_acc: 0.9843 - val_f1_m: 0.0128\n",
      "Epoch 27/100\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.0193 - acc: 0.9930 - f1_m: 0.8948 - val_loss: 0.1083 - val_acc: 0.9734 - val_f1_m: 0.0166\n",
      "Epoch 28/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0137 - acc: 0.9953 - f1_m: 0.9101 - val_loss: 0.0774 - val_acc: 0.9854 - val_f1_m: 0.0086\n",
      "Epoch 29/100\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.0139 - acc: 0.9947 - f1_m: 0.8975 - val_loss: 0.0998 - val_acc: 0.9873 - val_f1_m: 0.0048\n",
      "Epoch 30/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0144 - acc: 0.9951 - f1_m: 0.9174 - val_loss: 0.0760 - val_acc: 0.9860 - val_f1_m: 0.0074\n",
      "Epoch 31/100\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.0137 - acc: 0.9954 - f1_m: 0.9075 - val_loss: 0.1121 - val_acc: 0.9613 - val_f1_m: 0.0149\n",
      "Epoch 32/100\n",
      "29420/29420 [==============================] - 3s 90us/step - loss: 0.0139 - acc: 0.9949 - f1_m: 0.9098 - val_loss: 0.0743 - val_acc: 0.9858 - val_f1_m: 0.0058\n",
      "Epoch 33/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0132 - acc: 0.9954 - f1_m: 0.9085 - val_loss: 0.0818 - val_acc: 0.9882 - val_f1_m: 0.0106\n",
      "Epoch 34/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0186 - acc: 0.9942 - f1_m: 0.8887 - val_loss: 0.0929 - val_acc: 0.9831 - val_f1_m: 0.0111\n",
      "Epoch 35/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0121 - acc: 0.9958 - f1_m: 0.9180 - val_loss: 0.1583 - val_acc: 0.9568 - val_f1_m: 0.0119\n",
      "Epoch 36/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0123 - acc: 0.9956 - f1_m: 0.9085 - val_loss: 0.0738 - val_acc: 0.9905 - val_f1_m: 0.0090\n",
      "Epoch 37/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0134 - acc: 0.9955 - f1_m: 0.9069 - val_loss: 0.1018 - val_acc: 0.9814 - val_f1_m: 0.0096\n",
      "Epoch 38/100\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.0108 - acc: 0.9967 - f1_m: 0.9343 - val_loss: 0.0887 - val_acc: 0.9868 - val_f1_m: 0.0077\n",
      "Epoch 39/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0116 - acc: 0.9958 - f1_m: 0.8986 - val_loss: 0.1034 - val_acc: 0.9761 - val_f1_m: 0.0099\n",
      "Epoch 40/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0076 - acc: 0.9975 - f1_m: 0.9334 - val_loss: 0.1328 - val_acc: 0.9834 - val_f1_m: 0.0080\n",
      "Epoch 41/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0173 - acc: 0.9936 - f1_m: 0.8810 - val_loss: 0.0698 - val_acc: 0.9883 - val_f1_m: 0.0099\n",
      "Epoch 42/100\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.0094 - acc: 0.9967 - f1_m: 0.9179 - val_loss: 0.0733 - val_acc: 0.9884 - val_f1_m: 0.0093\n",
      "Epoch 43/100\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.0105 - acc: 0.9966 - f1_m: 0.9299 - val_loss: 0.1032 - val_acc: 0.9779 - val_f1_m: 0.0118\n",
      "Epoch 44/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0103 - acc: 0.9967 - f1_m: 0.9353 - val_loss: 0.0788 - val_acc: 0.9869 - val_f1_m: 0.0139\n",
      "Epoch 45/100\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.0078 - acc: 0.9975 - f1_m: 0.9218 - val_loss: 0.0799 - val_acc: 0.9888 - val_f1_m: 0.0115\n",
      "Epoch 46/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0097 - acc: 0.9968 - f1_m: 0.9220 - val_loss: 0.0578 - val_acc: 0.9863 - val_f1_m: 0.0038\n",
      "Epoch 47/100\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.0093 - acc: 0.9969 - f1_m: 0.9249 - val_loss: 0.1723 - val_acc: 0.9680 - val_f1_m: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.0120 - acc: 0.9957 - f1_m: 0.9063 - val_loss: 0.0889 - val_acc: 0.9806 - val_f1_m: 0.0203\n",
      "Epoch 49/100\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.0089 - acc: 0.9970 - f1_m: 0.9303 - val_loss: 0.0779 - val_acc: 0.9801 - val_f1_m: 0.0150\n",
      "Epoch 50/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0094 - acc: 0.9968 - f1_m: 0.9250 - val_loss: 0.0926 - val_acc: 0.9795 - val_f1_m: 0.0116\n",
      "Epoch 51/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0080 - acc: 0.9972 - f1_m: 0.9391 - val_loss: 0.1169 - val_acc: 0.9808 - val_f1_m: 0.0126\n",
      "Epoch 52/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0079 - acc: 0.9969 - f1_m: 0.9230 - val_loss: 0.1107 - val_acc: 0.9812 - val_f1_m: 0.0084\n",
      "Epoch 53/100\n",
      "29420/29420 [==============================] - 3s 90us/step - loss: 0.0075 - acc: 0.9976 - f1_m: 0.9416 - val_loss: 0.1502 - val_acc: 0.9716 - val_f1_m: 0.0153\n",
      "Epoch 54/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0077 - acc: 0.9976 - f1_m: 0.9325 - val_loss: 0.1133 - val_acc: 0.9791 - val_f1_m: 0.0139\n",
      "Epoch 55/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0119 - acc: 0.9962 - f1_m: 0.9175 - val_loss: 0.0702 - val_acc: 0.9917 - val_f1_m: 0.0019\n",
      "Epoch 56/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0137 - acc: 0.9954 - f1_m: 0.8954 - val_loss: 0.1100 - val_acc: 0.9774 - val_f1_m: 0.0089\n",
      "Epoch 57/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0057 - acc: 0.9980 - f1_m: 0.9423 - val_loss: 0.0944 - val_acc: 0.9867 - val_f1_m: 0.0109\n",
      "Epoch 58/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0092 - acc: 0.9970 - f1_m: 0.9271 - val_loss: 0.1076 - val_acc: 0.9829 - val_f1_m: 0.0138\n",
      "Epoch 59/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0043 - acc: 0.9986 - f1_m: 0.9481 - val_loss: 0.1049 - val_acc: 0.9907 - val_f1_m: 0.0038\n",
      "Epoch 60/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0067 - acc: 0.9977 - f1_m: 0.9193 - val_loss: 0.0994 - val_acc: 0.9837 - val_f1_m: 0.0090\n",
      "Epoch 61/100\n",
      "29420/29420 [==============================] - 3s 86us/step - loss: 0.0083 - acc: 0.9971 - f1_m: 0.9246 - val_loss: 0.0831 - val_acc: 0.9892 - val_f1_m: 0.0112\n",
      "Epoch 62/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0071 - acc: 0.9978 - f1_m: 0.9381 - val_loss: 0.1188 - val_acc: 0.9758 - val_f1_m: 0.0152\n",
      "Epoch 63/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0076 - acc: 0.9974 - f1_m: 0.9392 - val_loss: 0.1091 - val_acc: 0.9771 - val_f1_m: 0.0125\n",
      "Epoch 64/100\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.0048 - acc: 0.9988 - f1_m: 0.9524 - val_loss: 0.1154 - val_acc: 0.9752 - val_f1_m: 0.0118\n",
      "Epoch 65/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0058 - acc: 0.9981 - f1_m: 0.9377 - val_loss: 0.1136 - val_acc: 0.9788 - val_f1_m: 0.0157\n",
      "Epoch 66/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0102 - acc: 0.9972 - f1_m: 0.9391 - val_loss: 0.0886 - val_acc: 0.9842 - val_f1_m: 0.0090\n",
      "Epoch 67/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0059 - acc: 0.9981 - f1_m: 0.9302 - val_loss: 0.1121 - val_acc: 0.9854 - val_f1_m: 0.0072\n",
      "Epoch 68/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0097 - acc: 0.9971 - f1_m: 0.9212 - val_loss: 0.0968 - val_acc: 0.9831 - val_f1_m: 0.0112\n",
      "Epoch 69/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0061 - acc: 0.9982 - f1_m: 0.9460 - val_loss: 0.1044 - val_acc: 0.9846 - val_f1_m: 0.0131\n",
      "Epoch 70/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0044 - acc: 0.9985 - f1_m: 0.9502 - val_loss: 0.0965 - val_acc: 0.9915 - val_f1_m: 0.0102\n",
      "Epoch 71/100\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 0.0051 - acc: 0.9983 - f1_m: 0.9305 - val_loss: 0.1891 - val_acc: 0.9701 - val_f1_m: 0.0140\n",
      "Epoch 72/100\n",
      "29420/29420 [==============================] - 3s 90us/step - loss: 0.0078 - acc: 0.9973 - f1_m: 0.9393 - val_loss: 0.1074 - val_acc: 0.9900 - val_f1_m: 0.0090\n",
      "Epoch 73/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0077 - acc: 0.9977 - f1_m: 0.9394 - val_loss: 0.0747 - val_acc: 0.9845 - val_f1_m: 0.0107\n",
      "Epoch 74/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 0.0069 - acc: 0.9973 - f1_m: 0.9411 - val_loss: 0.0915 - val_acc: 0.9848 - val_f1_m: 0.0088\n",
      "Epoch 75/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0056 - acc: 0.9983 - f1_m: 0.9299 - val_loss: 0.0805 - val_acc: 0.9857 - val_f1_m: 0.0096\n",
      "Epoch 76/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 0.0079 - acc: 0.9977 - f1_m: 0.9385 - val_loss: 0.0607 - val_acc: 0.9870 - val_f1_m: 0.0074\n",
      "Epoch 77/100\n",
      "29420/29420 [==============================] - 3s 90us/step - loss: 0.0044 - acc: 0.9987 - f1_m: 0.9539 - val_loss: 0.1169 - val_acc: 0.9830 - val_f1_m: 0.0163\n",
      "Epoch 78/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 1.3885e-04 - acc: 1.0000 - f1_m: 0.9563 - val_loss: 0.1557 - val_acc: 0.9825 - val_f1_m: 0.0155\n",
      "Epoch 79/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 8.0147e-06 - acc: 1.0000 - f1_m: 0.9478 - val_loss: 0.2038 - val_acc: 0.9851 - val_f1_m: 0.0144\n",
      "Epoch 80/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 2.8645e-07 - acc: 1.0000 - f1_m: 0.9587 - val_loss: 0.2223 - val_acc: 0.9851 - val_f1_m: 0.0144\n",
      "Epoch 81/100\n",
      "29420/29420 [==============================] - 3s 90us/step - loss: 1.4512e-07 - acc: 1.0000 - f1_m: 0.9565 - val_loss: 0.2318 - val_acc: 0.9853 - val_f1_m: 0.0144\n",
      "Epoch 82/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 8.9965e-08 - acc: 1.0000 - f1_m: 0.9587 - val_loss: 0.2398 - val_acc: 0.9853 - val_f1_m: 0.0144\n",
      "Epoch 83/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 6.1139e-08 - acc: 1.0000 - f1_m: 0.9652 - val_loss: 0.2461 - val_acc: 0.9853 - val_f1_m: 0.0144\n",
      "Epoch 84/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 4.5689e-08 - acc: 1.0000 - f1_m: 0.9565 - val_loss: 0.2513 - val_acc: 0.9853 - val_f1_m: 0.0144\n",
      "Epoch 85/100\n",
      "29420/29420 [==============================] - 2s 82us/step - loss: 3.6201e-08 - acc: 1.0000 - f1_m: 0.9717 - val_loss: 0.2556 - val_acc: 0.9854 - val_f1_m: 0.0144\n",
      "Epoch 86/100\n",
      "29420/29420 [==============================] - 2s 85us/step - loss: 2.8927e-08 - acc: 1.0000 - f1_m: 0.9717 - val_loss: 0.2594 - val_acc: 0.9854 - val_f1_m: 0.0144\n",
      "Epoch 87/100\n",
      "29420/29420 [==============================] - 3s 86us/step - loss: 2.3251e-08 - acc: 1.0000 - f1_m: 0.9674 - val_loss: 0.2631 - val_acc: 0.9855 - val_f1_m: 0.0144\n",
      "Epoch 88/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 1.8814e-08 - acc: 1.0000 - f1_m: 0.9674 - val_loss: 0.2662 - val_acc: 0.9857 - val_f1_m: 0.0147\n",
      "Epoch 89/100\n",
      "29420/29420 [==============================] - 3s 90us/step - loss: 1.5377e-08 - acc: 1.0000 - f1_m: 0.9457 - val_loss: 0.2691 - val_acc: 0.9858 - val_f1_m: 0.0147\n",
      "Epoch 90/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 1.2695e-08 - acc: 1.0000 - f1_m: 0.9630 - val_loss: 0.2724 - val_acc: 0.9858 - val_f1_m: 0.0147\n",
      "Epoch 91/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 1.0461e-08 - acc: 1.0000 - f1_m: 0.9696 - val_loss: 0.2752 - val_acc: 0.9859 - val_f1_m: 0.0147\n",
      "Epoch 92/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 8.6530e-09 - acc: 1.0000 - f1_m: 0.9630 - val_loss: 0.2786 - val_acc: 0.9859 - val_f1_m: 0.0147\n",
      "Epoch 93/100\n",
      "29420/29420 [==============================] - 3s 87us/step - loss: 7.1451e-09 - acc: 1.0000 - f1_m: 0.9609 - val_loss: 0.2815 - val_acc: 0.9858 - val_f1_m: 0.0147\n",
      "Epoch 94/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 5.9193e-09 - acc: 1.0000 - f1_m: 0.9609 - val_loss: 0.2845 - val_acc: 0.9857 - val_f1_m: 0.0147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "29420/29420 [==============================] - 3s 90us/step - loss: 4.9419e-09 - acc: 1.0000 - f1_m: 0.9652 - val_loss: 0.2868 - val_acc: 0.9860 - val_f1_m: 0.0147\n",
      "Epoch 96/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 4.1110e-09 - acc: 1.0000 - f1_m: 0.9717 - val_loss: 0.2897 - val_acc: 0.9859 - val_f1_m: 0.0147\n",
      "Epoch 97/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 3.3832e-09 - acc: 1.0000 - f1_m: 0.9674 - val_loss: 0.2923 - val_acc: 0.9859 - val_f1_m: 0.0147\n",
      "Epoch 98/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 2.7923e-09 - acc: 1.0000 - f1_m: 0.9674 - val_loss: 0.2950 - val_acc: 0.9858 - val_f1_m: 0.0147\n",
      "Epoch 99/100\n",
      "29420/29420 [==============================] - 3s 88us/step - loss: 2.3347e-09 - acc: 1.0000 - f1_m: 0.9565 - val_loss: 0.2973 - val_acc: 0.9857 - val_f1_m: 0.0134\n",
      "Epoch 100/100\n",
      "29420/29420 [==============================] - 3s 89us/step - loss: 1.9564e-09 - acc: 1.0000 - f1_m: 0.9717 - val_loss: 0.2996 - val_acc: 0.9857 - val_f1_m: 0.0134\n",
      "33333/33333 [==============================] - 1s 21us/step\n",
      "Test score: 0.2996316272663492\n",
      "Test accuracy: 0.9857498407363892\n",
      "Test F1: 0.013435699045658112\n"
     ]
    }
   ],
   "source": [
    "def get_model(learning_rate):\n",
    "    # First Half\n",
    "    first_half = Input(shape=(199,))\n",
    "    x = Dense(150, activation='relu')(first_half)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dense(75, activation='relu')(x)\n",
    "    out_first = Dense(50, activation='relu')(x)\n",
    "\n",
    "    second_half = Input(shape=(199,))\n",
    "    x = Dense(100, activation='relu')(second_half)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    out_second = Dense(25, activation='relu')(x)\n",
    "\n",
    "    concatenated = concatenate([out_first, out_second])\n",
    "    x = Dense(75, activation='relu')(concatenated)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    x = Dense(20, activation='relu')(x)\n",
    "    out_final = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = K.Model([first_half, second_half], out_final)\n",
    "\n",
    "    # Hyperparameters: learning_rate, beta_1, beta_2, epsilon\n",
    "    opt = K.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc', f1_m])\n",
    "\n",
    "    return model\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = get_model(learning_rate=learning_rate)\n",
    "history = model.fit(train_seq_tok_split, train_label, \n",
    "                    batch_size=batch_size, epochs=epochs, \n",
    "                    validation_data=(test_seq_tok_split, test_label))\n",
    "score, acc, f1 = model.evaluate(test_seq_tok_split, test_label, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "print('Test F1:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4hc_proj4",
   "language": "python",
   "name": "ml4hc_proj4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
