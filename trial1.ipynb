{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_seq shape: (29420,)\n",
      "test_seq shape: (33333,)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence, text\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#train_data_source = './exercise_data/human_dna_train_small.csv'\n",
    "train_data_source = './exercise_data/human_dna_train_split_5_95.csv'\n",
    "val_data_source = './exercise_data/human_dna_validation_split.csv'\n",
    "test_data_source = './exercise_data/human_dna_test_split.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_data_source, header=0)\n",
    "test_df = pd.read_csv(test_data_source, header=0)\n",
    "\n",
    "train_seq = train_df['sequences']\n",
    "train_label = train_df['labels']\n",
    "test_seq = test_df['sequences']\n",
    "test_label = test_df['labels']\n",
    "\n",
    "# Preprocess\n",
    "tk = text.Tokenizer(char_level=True)\n",
    "tk.fit_on_texts(train_seq)\n",
    "\n",
    "train_seq_tok = tk.texts_to_sequences(train_seq)\n",
    "test_seq_tok = tk.texts_to_sequences(test_seq)\n",
    "\n",
    "train_seq = np.array(train_seq)\n",
    "train_seq_tok = np.array(train_seq_tok)\n",
    "train_label = np.array(train_label)\n",
    "test_seq = np.array(test_seq)\n",
    "test_seq_tok = np.array(test_seq_tok)\n",
    "test_label = np.array(test_label)\n",
    "\n",
    "print('train_seq shape:', train_seq.shape)\n",
    "print('test_seq shape:', test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label[train_label<0]=0\n",
    "test_label[test_label<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_tok = train_seq_tok - np.ones(shape=train_seq_tok.shape)\n",
    "test_seq_tok = test_seq_tok - np.ones(shape=test_seq_tok.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 3., 1., 1., 2., 1., 2., 2., 0., 0., 1., 1., 2., 3., 1., 1., 3.,\n",
       "       0., 0., 2., 0., 2., 2., 1., 0., 2., 2., 0., 3., 1., 0., 2., 2., 1.,\n",
       "       3., 2., 1., 0., 1., 2., 2., 2., 1., 1., 3., 0., 1., 0., 0., 2., 3.,\n",
       "       1., 1., 1., 0., 0., 3., 0., 0., 2., 1., 2., 3., 1., 0., 2., 2., 0.,\n",
       "       2., 0., 0., 2., 1., 3., 1., 2., 2., 2., 1., 1., 2., 1., 1., 1., 1.,\n",
       "       3., 1., 2., 0., 1., 0., 0., 3., 3., 1., 2., 1., 0., 3., 1., 2., 0.,\n",
       "       0., 1., 2., 0., 2., 0., 2., 2., 3., 1., 2., 0., 1., 1., 1., 1., 3.,\n",
       "       1., 3., 1., 0., 2., 1., 2., 2., 2., 2., 0., 2., 1., 3., 0., 2., 1.,\n",
       "       1., 2., 2., 2., 1., 1., 2., 3., 1., 2., 3., 1., 1., 1., 1., 1., 3.,\n",
       "       0., 2., 2., 3., 1., 2., 1., 1., 1., 1., 1., 1., 3., 1., 1., 2., 3.,\n",
       "       1., 2., 3., 0., 3., 0., 0., 0., 3., 0., 3., 0., 2., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 2., 3., 3., 1., 1., 1., 2., 2., 1., 0., 1., 3.,\n",
       "       3., 0., 3., 3., 3., 0., 3., 1., 1., 3., 1., 1., 0., 2., 2., 2., 3.,\n",
       "       1., 0., 0., 3., 3., 0., 1., 2., 2., 2., 1., 2., 3., 1., 0., 3., 1.,\n",
       "       0., 0., 1., 1., 3., 1., 1., 2., 1., 0., 0., 3., 3., 1., 2., 3., 0.,\n",
       "       3., 0., 1., 3., 0., 3., 3., 0., 0., 3., 3., 0., 2., 3., 0., 2., 1.,\n",
       "       2., 2., 0., 0., 0., 2., 0., 3., 2., 3., 0., 0., 1., 1., 2., 1., 1.,\n",
       "       0., 3., 0., 2., 2., 1., 2., 1., 3., 1., 2., 2., 0., 1., 2., 2., 2.,\n",
       "       0., 2., 3., 1., 2., 0., 2., 2., 3., 0., 0., 1., 3., 1., 3., 3., 0.,\n",
       "       2., 0., 1., 1., 0., 3., 3., 0., 1., 2., 3., 1., 3., 0., 0., 0., 2.,\n",
       "       2., 2., 1., 2., 2., 3., 3., 1., 1., 2., 2., 3., 2., 0., 2., 0., 1.,\n",
       "       2., 1., 0., 3., 1., 3., 3., 0., 2., 1., 2., 2., 0., 3., 1., 2., 2.,\n",
       "       1., 2., 0., 0., 3., 1., 1., 3., 1., 3., 3., 1., 2., 3., 3., 0., 2.,\n",
       "       1., 3., 3., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 29420 samples, validate on 33333 samples\n",
      "Epoch 1/100\n",
      "29420/29420 [==============================] - 9s 292us/step - loss: 0.2116 - acc: 0.9492 - val_loss: 0.0731 - val_acc: 0.9969\n",
      "Epoch 2/100\n",
      "29420/29420 [==============================] - 8s 281us/step - loss: 0.1885 - acc: 0.9500 - val_loss: 0.0416 - val_acc: 0.9969\n",
      "Epoch 3/100\n",
      "29420/29420 [==============================] - 8s 279us/step - loss: 0.1834 - acc: 0.9500 - val_loss: 0.0975 - val_acc: 0.9969\n",
      "Epoch 4/100\n",
      "29420/29420 [==============================] - 8s 284us/step - loss: 0.1789 - acc: 0.9500 - val_loss: 0.0459 - val_acc: 0.9969\n",
      "Epoch 5/100\n",
      "29420/29420 [==============================] - 8s 282us/step - loss: 0.1760 - acc: 0.9499 - val_loss: 0.0451 - val_acc: 0.9969\n",
      "Epoch 6/100\n",
      "29420/29420 [==============================] - 8s 277us/step - loss: 0.1734 - acc: 0.9500 - val_loss: 0.0991 - val_acc: 0.9969\n",
      "Epoch 7/100\n",
      "29420/29420 [==============================] - 8s 277us/step - loss: 0.1710 - acc: 0.9500 - val_loss: 0.0466 - val_acc: 0.9967\n",
      "Epoch 8/100\n",
      "29420/29420 [==============================] - 8s 284us/step - loss: 0.1681 - acc: 0.9500 - val_loss: 0.0446 - val_acc: 0.9969\n",
      "Epoch 9/100\n",
      "29420/29420 [==============================] - 8s 277us/step - loss: 0.1657 - acc: 0.9504 - val_loss: 0.0849 - val_acc: 0.9891\n",
      "Epoch 10/100\n",
      "29420/29420 [==============================] - 8s 282us/step - loss: 0.1635 - acc: 0.9506 - val_loss: 0.0360 - val_acc: 0.9968\n",
      "Epoch 11/100\n",
      "29420/29420 [==============================] - 8s 282us/step - loss: 0.1611 - acc: 0.9509 - val_loss: 0.0286 - val_acc: 0.9968\n",
      "Epoch 12/100\n",
      "29420/29420 [==============================] - 8s 279us/step - loss: 0.1586 - acc: 0.9516 - val_loss: 0.0498 - val_acc: 0.9968\n",
      "Epoch 13/100\n",
      "29420/29420 [==============================] - 8s 277us/step - loss: 0.1586 - acc: 0.9520 - val_loss: 0.0628 - val_acc: 0.9963\n",
      "Epoch 14/100\n",
      "29420/29420 [==============================] - 8s 283us/step - loss: 0.1568 - acc: 0.9527 - val_loss: 0.0811 - val_acc: 0.9950\n",
      "Epoch 15/100\n",
      "29420/29420 [==============================] - 8s 282us/step - loss: 0.1510 - acc: 0.9533 - val_loss: 0.0408 - val_acc: 0.9952\n",
      "Epoch 16/100\n",
      "29420/29420 [==============================] - 8s 283us/step - loss: 0.1483 - acc: 0.9541 - val_loss: 0.0468 - val_acc: 0.9950\n",
      "Epoch 17/100\n",
      "29420/29420 [==============================] - 8s 274us/step - loss: 0.1453 - acc: 0.9544 - val_loss: 0.0524 - val_acc: 0.9965\n",
      "Epoch 18/100\n",
      "29420/29420 [==============================] - 8s 275us/step - loss: 0.1437 - acc: 0.9539 - val_loss: 0.0506 - val_acc: 0.9951\n",
      "Epoch 19/100\n",
      "29420/29420 [==============================] - 8s 270us/step - loss: 0.1424 - acc: 0.9557 - val_loss: 0.0529 - val_acc: 0.9953\n",
      "Epoch 20/100\n",
      "29420/29420 [==============================] - 8s 272us/step - loss: 0.1378 - acc: 0.9570 - val_loss: 0.0577 - val_acc: 0.9920\n",
      "Epoch 21/100\n",
      "29420/29420 [==============================] - 8s 279us/step - loss: 0.1342 - acc: 0.9576 - val_loss: 0.0614 - val_acc: 0.9860\n",
      "Epoch 22/100\n",
      "29420/29420 [==============================] - 8s 272us/step - loss: 0.1314 - acc: 0.9582 - val_loss: 0.0644 - val_acc: 0.9961\n",
      "Epoch 23/100\n",
      "29420/29420 [==============================] - 8s 279us/step - loss: 0.1254 - acc: 0.9591 - val_loss: 0.0664 - val_acc: 0.9909\n",
      "Epoch 24/100\n",
      "29420/29420 [==============================] - 8s 283us/step - loss: 0.1275 - acc: 0.9596 - val_loss: 0.0427 - val_acc: 0.9967\n",
      "Epoch 25/100\n",
      "29420/29420 [==============================] - 8s 280us/step - loss: 0.1247 - acc: 0.9605 - val_loss: 0.0539 - val_acc: 0.9879\n",
      "Epoch 26/100\n",
      "29420/29420 [==============================] - 8s 279us/step - loss: 0.1189 - acc: 0.9626 - val_loss: 0.0392 - val_acc: 0.9950\n",
      "Epoch 27/100\n",
      "29420/29420 [==============================] - 8s 273us/step - loss: 0.1191 - acc: 0.9615 - val_loss: 0.0467 - val_acc: 0.9939\n",
      "Epoch 28/100\n",
      "29420/29420 [==============================] - 8s 279us/step - loss: 0.1243 - acc: 0.9618 - val_loss: 0.0413 - val_acc: 0.9959\n",
      "Epoch 29/100\n",
      "29420/29420 [==============================] - 8s 279us/step - loss: 0.1244 - acc: 0.9615 - val_loss: 0.0568 - val_acc: 0.9931\n",
      "Epoch 30/100\n",
      "29420/29420 [==============================] - 8s 269us/step - loss: 0.1147 - acc: 0.9631 - val_loss: 0.0397 - val_acc: 0.9924\n",
      "Epoch 31/100\n",
      "29420/29420 [==============================] - 8s 283us/step - loss: 0.1156 - acc: 0.9630 - val_loss: 0.0403 - val_acc: 0.9942\n",
      "Epoch 32/100\n",
      "29420/29420 [==============================] - 8s 280us/step - loss: 0.1148 - acc: 0.9624 - val_loss: 0.0498 - val_acc: 0.9921\n",
      "Epoch 33/100\n",
      "29420/29420 [==============================] - 8s 273us/step - loss: 0.1096 - acc: 0.9637 - val_loss: 0.0750 - val_acc: 0.9836\n",
      "Epoch 34/100\n",
      "29420/29420 [==============================] - 8s 276us/step - loss: 0.1067 - acc: 0.9642 - val_loss: 0.0498 - val_acc: 0.9944\n",
      "Epoch 35/100\n",
      "29420/29420 [==============================] - 8s 279us/step - loss: 0.1058 - acc: 0.9646 - val_loss: 0.0576 - val_acc: 0.9905\n",
      "Epoch 36/100\n",
      "29420/29420 [==============================] - 8s 270us/step - loss: 0.1052 - acc: 0.9644 - val_loss: 0.0634 - val_acc: 0.9877\n",
      "Epoch 37/100\n",
      "29420/29420 [==============================] - 8s 283us/step - loss: 0.1045 - acc: 0.9644 - val_loss: 0.0572 - val_acc: 0.9932\n",
      "Epoch 38/100\n",
      "29420/29420 [==============================] - 8s 271us/step - loss: 0.1111 - acc: 0.9634 - val_loss: 0.0468 - val_acc: 0.9931\n",
      "Epoch 39/100\n",
      "29420/29420 [==============================] - 8s 280us/step - loss: 0.1017 - acc: 0.9654 - val_loss: 0.0530 - val_acc: 0.9890\n",
      "Epoch 40/100\n",
      "29420/29420 [==============================] - 8s 276us/step - loss: 0.0970 - acc: 0.9660 - val_loss: 0.0558 - val_acc: 0.9907\n",
      "Epoch 41/100\n",
      "29420/29420 [==============================] - 8s 274us/step - loss: 0.0964 - acc: 0.9658 - val_loss: 0.0643 - val_acc: 0.9858\n",
      "Epoch 42/100\n",
      "29420/29420 [==============================] - 8s 274us/step - loss: 0.0994 - acc: 0.9666 - val_loss: 0.0652 - val_acc: 0.9874\n",
      "Epoch 43/100\n",
      "29420/29420 [==============================] - 8s 272us/step - loss: 0.0970 - acc: 0.9666 - val_loss: 0.0415 - val_acc: 0.9938\n",
      "Epoch 44/100\n",
      "29420/29420 [==============================] - 8s 282us/step - loss: 0.0979 - acc: 0.9652 - val_loss: 0.0481 - val_acc: 0.9916\n",
      "Epoch 45/100\n",
      "29420/29420 [==============================] - 8s 270us/step - loss: 0.0944 - acc: 0.9672 - val_loss: 0.0419 - val_acc: 0.9918\n",
      "Epoch 46/100\n",
      "29420/29420 [==============================] - 8s 277us/step - loss: 0.0950 - acc: 0.9663 - val_loss: 0.0425 - val_acc: 0.9942\n",
      "Epoch 47/100\n",
      "29420/29420 [==============================] - 8s 282us/step - loss: 0.0909 - acc: 0.9673 - val_loss: 0.0462 - val_acc: 0.9909\n",
      "Epoch 48/100\n",
      "29420/29420 [==============================] - 8s 280us/step - loss: 0.0924 - acc: 0.9662 - val_loss: 0.0620 - val_acc: 0.9861\n",
      "Epoch 49/100\n",
      "29420/29420 [==============================] - 8s 271us/step - loss: 0.0930 - acc: 0.9659 - val_loss: 0.0591 - val_acc: 0.9863\n",
      "Epoch 50/100\n",
      "29420/29420 [==============================] - 8s 273us/step - loss: 0.0955 - acc: 0.9661 - val_loss: 0.0540 - val_acc: 0.9922\n",
      "Epoch 51/100\n",
      "29420/29420 [==============================] - 8s 278us/step - loss: 0.0880 - acc: 0.9676 - val_loss: 0.0623 - val_acc: 0.9904\n",
      "Epoch 52/100\n",
      "29420/29420 [==============================] - 8s 281us/step - loss: 0.0868 - acc: 0.9671 - val_loss: 0.0483 - val_acc: 0.9912\n",
      "Epoch 53/100\n",
      "29420/29420 [==============================] - 8s 279us/step - loss: 0.0836 - acc: 0.9679 - val_loss: 0.0698 - val_acc: 0.9840\n",
      "Epoch 54/100\n",
      "29420/29420 [==============================] - 8s 278us/step - loss: 0.0829 - acc: 0.9678 - val_loss: 0.0528 - val_acc: 0.9915\n",
      "Epoch 55/100\n",
      "29420/29420 [==============================] - 8s 271us/step - loss: 0.0875 - acc: 0.9682 - val_loss: 0.0500 - val_acc: 0.9921\n",
      "Epoch 56/100\n",
      "29420/29420 [==============================] - 8s 276us/step - loss: 0.0891 - acc: 0.9665 - val_loss: 0.0563 - val_acc: 0.9894\n",
      "Epoch 57/100\n",
      "29420/29420 [==============================] - 8s 273us/step - loss: 0.0851 - acc: 0.9666 - val_loss: 0.0540 - val_acc: 0.9907\n",
      "Epoch 58/100\n",
      "29420/29420 [==============================] - 8s 276us/step - loss: 0.0838 - acc: 0.9670 - val_loss: 0.0518 - val_acc: 0.9906\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29420/29420 [==============================] - 8s 280us/step - loss: 0.0847 - acc: 0.9674 - val_loss: 0.0508 - val_acc: 0.9915\n",
      "Epoch 60/100\n",
      "29420/29420 [==============================] - 8s 271us/step - loss: 0.0803 - acc: 0.9682 - val_loss: 0.0541 - val_acc: 0.9898\n",
      "Epoch 61/100\n",
      "29420/29420 [==============================] - 8s 276us/step - loss: 0.0770 - acc: 0.9687 - val_loss: 0.0450 - val_acc: 0.9949\n",
      "Epoch 62/100\n",
      "29420/29420 [==============================] - 8s 275us/step - loss: 0.0825 - acc: 0.9672 - val_loss: 0.0666 - val_acc: 0.9901\n",
      "Epoch 63/100\n",
      "29420/29420 [==============================] - 8s 273us/step - loss: 0.0781 - acc: 0.9685 - val_loss: 0.0590 - val_acc: 0.9899\n",
      "Epoch 64/100\n",
      "29420/29420 [==============================] - 8s 278us/step - loss: 0.0765 - acc: 0.9688 - val_loss: 0.0802 - val_acc: 0.9864\n",
      "Epoch 65/100\n",
      "29420/29420 [==============================] - 8s 283us/step - loss: 0.0782 - acc: 0.9678 - val_loss: 0.0524 - val_acc: 0.9904\n",
      "Epoch 66/100\n",
      "29420/29420 [==============================] - 8s 267us/step - loss: 0.0754 - acc: 0.9680 - val_loss: 0.0516 - val_acc: 0.9912\n",
      "Epoch 67/100\n",
      "29420/29420 [==============================] - 7s 250us/step - loss: 0.0737 - acc: 0.9683 - val_loss: 0.0560 - val_acc: 0.9899\n",
      "Epoch 68/100\n",
      "29420/29420 [==============================] - 8s 258us/step - loss: 0.0726 - acc: 0.9688 - val_loss: 0.0828 - val_acc: 0.9804\n",
      "Epoch 69/100\n",
      "29420/29420 [==============================] - 8s 272us/step - loss: 0.0721 - acc: 0.9689 - val_loss: 0.0538 - val_acc: 0.9937\n",
      "Epoch 70/100\n",
      "29420/29420 [==============================] - 8s 273us/step - loss: 0.0744 - acc: 0.9684 - val_loss: 0.0497 - val_acc: 0.9924\n",
      "Epoch 71/100\n",
      "29420/29420 [==============================] - 8s 260us/step - loss: 0.0734 - acc: 0.9681 - val_loss: 0.0643 - val_acc: 0.9879\n",
      "Epoch 72/100\n",
      "29420/29420 [==============================] - 8s 280us/step - loss: 0.0722 - acc: 0.9682 - val_loss: 0.0696 - val_acc: 0.9923\n",
      "Epoch 73/100\n",
      "29420/29420 [==============================] - 8s 274us/step - loss: 0.0698 - acc: 0.9692 - val_loss: 0.0705 - val_acc: 0.9859\n",
      "Epoch 74/100\n",
      "29420/29420 [==============================] - 8s 271us/step - loss: 0.0710 - acc: 0.9700 - val_loss: 0.0529 - val_acc: 0.9910\n",
      "Epoch 75/100\n",
      "29420/29420 [==============================] - 8s 274us/step - loss: 0.0654 - acc: 0.9704 - val_loss: 0.0662 - val_acc: 0.9902\n",
      "Epoch 76/100\n",
      "29420/29420 [==============================] - 8s 267us/step - loss: 0.0671 - acc: 0.9689 - val_loss: 0.0531 - val_acc: 0.9933\n",
      "Epoch 77/100\n",
      "29420/29420 [==============================] - 8s 276us/step - loss: 0.0683 - acc: 0.9699 - val_loss: 0.0697 - val_acc: 0.9903\n",
      "Epoch 78/100\n",
      "29420/29420 [==============================] - 8s 272us/step - loss: 0.0655 - acc: 0.9695 - val_loss: 0.0703 - val_acc: 0.9899\n",
      "Epoch 79/100\n",
      "29420/29420 [==============================] - 8s 269us/step - loss: 0.0653 - acc: 0.9693 - val_loss: 0.0657 - val_acc: 0.9902\n",
      "Epoch 80/100\n",
      "29420/29420 [==============================] - 8s 275us/step - loss: 0.0715 - acc: 0.9679 - val_loss: 0.0434 - val_acc: 0.9944\n",
      "Epoch 81/100\n",
      "29420/29420 [==============================] - 8s 272us/step - loss: 0.0620 - acc: 0.9703 - val_loss: 0.0731 - val_acc: 0.9892\n",
      "Epoch 82/100\n",
      "29420/29420 [==============================] - 8s 276us/step - loss: 0.0622 - acc: 0.9701 - val_loss: 0.0638 - val_acc: 0.9903\n",
      "Epoch 83/100\n",
      "29420/29420 [==============================] - 8s 278us/step - loss: 0.0650 - acc: 0.9695 - val_loss: 0.0564 - val_acc: 0.9906\n",
      "Epoch 84/100\n",
      "29420/29420 [==============================] - 8s 274us/step - loss: 0.0608 - acc: 0.9705 - val_loss: 0.0585 - val_acc: 0.9933\n",
      "Epoch 85/100\n",
      "29420/29420 [==============================] - 8s 270us/step - loss: 0.0647 - acc: 0.9700 - val_loss: 0.0584 - val_acc: 0.9822\n",
      "Epoch 86/100\n",
      "29420/29420 [==============================] - 8s 270us/step - loss: 0.0626 - acc: 0.9696 - val_loss: 0.0767 - val_acc: 0.9885\n",
      "Epoch 87/100\n",
      "29420/29420 [==============================] - 8s 275us/step - loss: 0.0655 - acc: 0.9695 - val_loss: 0.0649 - val_acc: 0.9899\n",
      "Epoch 88/100\n",
      "29420/29420 [==============================] - 8s 273us/step - loss: 0.0619 - acc: 0.9708 - val_loss: 0.0546 - val_acc: 0.9942\n",
      "Epoch 89/100\n",
      "29420/29420 [==============================] - 8s 277us/step - loss: 0.0739 - acc: 0.9686 - val_loss: 0.0520 - val_acc: 0.9926\n",
      "Epoch 90/100\n",
      "29420/29420 [==============================] - 8s 275us/step - loss: 0.0659 - acc: 0.9703 - val_loss: 0.0632 - val_acc: 0.9866\n",
      "Epoch 91/100\n",
      "29420/29420 [==============================] - 8s 265us/step - loss: 0.0588 - acc: 0.9710 - val_loss: 0.0580 - val_acc: 0.9920\n",
      "Epoch 92/100\n",
      "29420/29420 [==============================] - 8s 271us/step - loss: 0.0610 - acc: 0.9703 - val_loss: 0.0486 - val_acc: 0.9917\n",
      "Epoch 93/100\n",
      "29420/29420 [==============================] - 8s 274us/step - loss: 0.0610 - acc: 0.9697 - val_loss: 0.0573 - val_acc: 0.9897\n",
      "Epoch 94/100\n",
      "29420/29420 [==============================] - 8s 275us/step - loss: 0.0600 - acc: 0.9708 - val_loss: 0.0542 - val_acc: 0.9889\n",
      "Epoch 95/100\n",
      "29420/29420 [==============================] - 8s 277us/step - loss: 0.0583 - acc: 0.9723 - val_loss: 0.0625 - val_acc: 0.9904\n",
      "Epoch 96/100\n",
      "29420/29420 [==============================] - 8s 280us/step - loss: 0.0613 - acc: 0.9710 - val_loss: 0.0619 - val_acc: 0.9892\n",
      "Epoch 97/100\n",
      "29420/29420 [==============================] - 8s 278us/step - loss: 0.0625 - acc: 0.9699 - val_loss: 0.0581 - val_acc: 0.9898\n",
      "Epoch 98/100\n",
      "29420/29420 [==============================] - 8s 277us/step - loss: 0.0640 - acc: 0.9706 - val_loss: 0.0460 - val_acc: 0.9941\n",
      "Epoch 99/100\n",
      "29420/29420 [==============================] - 8s 280us/step - loss: 0.0580 - acc: 0.9715 - val_loss: 0.0540 - val_acc: 0.9915\n",
      "Epoch 100/100\n",
      "29420/29420 [==============================] - 8s 277us/step - loss: 0.0582 - acc: 0.9707 - val_loss: 0.0656 - val_acc: 0.9791\n",
      "33333/33333 [==============================] - 2s 47us/step\n",
      "Test score: 0.06557901521069379\n",
      "Test accuracy: 0.9791197776794434\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "import keras as K\n",
    "\n",
    "# def recall_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#     recall = true_positives / (possible_positives + K.epsilon())\n",
    "#     return recall\n",
    "\n",
    "# def precision_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#     precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#     return precision\n",
    "\n",
    "# def f1_m(y_true, y_pred):\n",
    "#     precision = precision_m(y_true, y_pred)\n",
    "#     recall = recall_m(y_true, y_pred)\n",
    "#     return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# max_features = 20000\n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(300, activation='relu', input_shape=(398,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "opt = K.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(train_seq_tok, train_label, batch_size=batch_size, epochs=epochs, validation_data=(test_seq_tok, test_label))\n",
    "score, acc = model.evaluate(test_seq_tok, test_label, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4hc_proj4",
   "language": "python",
   "name": "ml4hc_proj4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
